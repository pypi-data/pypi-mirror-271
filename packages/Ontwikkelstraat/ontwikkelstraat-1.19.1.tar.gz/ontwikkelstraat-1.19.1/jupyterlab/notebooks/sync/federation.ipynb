{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Federatie\n",
    "Grote keuzes:\n",
    " - Transacties zijn immutable, globaal geindentificeerd met een UUID, per server voorzien van een automatisch ophogend ID in een transactie tabel omdat volgorde belangrijk kan zijn.\n",
    " - Werken we alleen maar met direct verbonden nodes (producer-consumer), of moeten nodes ook indirect met elkaar verbonden kunnen zijn (producer-proxy-...-consumer)?\n",
    "   - zodra we landelijk als centraal willen gebruiken, is dat eigenlijk al een proxy\n",
    "       1. T0: source produceert Transactie0\n",
    "       2. T1: source pusht naar landelijk\n",
    "       3. T2: destination pullt van landelijk alles vanaf begin der tijden: Transactie0\n",
    "       4. T3: source produceert Transactie1\n",
    "       5. T4: soure pusht naar landelijk\n",
    "       6. T5: destination pullt vanaf landelijk alles sinds T2: Transactie1\n",
    "       7. T6: source produceert Transactie2, Transactie3\n",
    "       8. T7: destination pullt vanaf landelijk alles sinds T5: geen\n",
    "       9. T8: source pusht Transactie2 en Transactie3 naar landelijk\n",
    "   - zoals te zien kunnen we niet met timestamps alleen werken.\n",
    "   - wat we wel kunnen aannemen is dat alle transacties die gezien/ontstaan worden door landelijk opvolgend zijn (append only log), en dat dus alle regels met een `ID > [laatst geziene transactie]` relevant zijn (waarbij ID relevant is per platform en niet over de verschillende platformen).\n",
    "       1. T0: source produceert Transactie0\n",
    "       2. T1: source pusht naar landelijk(id:0)\n",
    "       3. T2: destination pullt van landelijk alles vanaf begin der tijden: id > -1\n",
    "       4. T3: source produceert Transactie1\n",
    "       5. T4: soure pusht naar landelijk (id:1)\n",
    "       6. T5: destination pullt vanaf landelijk alles sinds Transactie1 (id > 0): Transactie1\n",
    "       7. T6: source produceert Transactie2, Transactie3\n",
    "       8. T7: destination pullt vanaf landelijk alles sinds Transactie1 (id:1): niets\n",
    "       9. T8: source pusht Transactie2(id:2) en Transactie3 (id:3) naar landelijk\n",
    "       10. T9: destination pullt vanaf landelijk alles sinds Transactie1 (id:1): Transactie2 en Transactie3\n",
    "\n",
    "# In- en outbox \n",
    "Een bron host (waar een item origine heeft) zet het item in een outbox, klaar om gelezen te worden. Het kan ook items pushen naar hosts die een abonnement hebben lopen.\n",
    "\n",
    "## pull mogelijkeden: postvakken met 'wijzigingen sinds'\n",
    "Een destination host kan een source host vragen om alles wat het klaar heeft liggen in de outbox op basis van een optionele transactie-gid. Alle transacties die op de bevraagde host zijn toegevoegd hebben een lokale id groter dan de lokale id van de meegegeven transactie-gid. De source of proxy host hoef niet alle resultaten te tonen om in redelijke batches te kunnen werken. Daarom moet een destination host eigenlijk altijd blijven doorvragen of er niet meer resultaten zijn, net zolang tot die er niet meer zijn. Dat scheelt volledige pagination met vaste aantallen, aangezien de webserver zelf kan beslissen welke batch-size het hanteerd omdat daar ook de zwaarte van de hosting ligt. Dat is niet aan de client om dat te beslissen.\n",
    "```sql\n",
    " select *\n",
    "   from transcation\n",
    "  where id > (select id from transaction where gid = {ref_gid})\n",
    "  order by id\n",
    "   limit 100\n",
    "```\n",
    "De `order by` is belangrijk, omdat voor pagination dit niet in random order mag komen. anders krijg je gaten.\n",
    "\n",
    "\n",
    "## push mogelijkheden: abonnementen\n",
    "Een abonnement is van een destination host bij een source host. De destination host verzoekt de source host om bij elke update van de outbox een push melding af te geven bij de destination host's inbox. \n",
    " - hier is later uitbreiding op te maken door filtering, maar vooralsnog is dat niet nodig.\n",
    "\n",
    "## push en pull door elkaar gebruiken \n",
    "Push en pull kan door elkaar gebruikt worden. De transacties hebben immers een unieke transactie gid en zijn immutable. Daarmee is een wijziging snel terug te vinden en deduplicatie toe te passen.\n",
    "Om mogelijke gaten op te lossen kunnen pushes aangevuld worden door af en toe een pull waar de destination bij de source alleen vraagt om de gids van toepasselijke transacties. De aanvragende destination host kijkt of er onbekende gids in de lijst voorkomen en vraagt de gegevens van alleen deze transacties in een nieuwe request op. Dit scheelt veel I/O overhead.\n",
    "\n",
    "## crossposten en transactiegids \n",
    "Aangezien transactie gids overal vandaan mogen komen kan een transactie van een derde host doorgegeven worden bij een decentrale opbouw (wanneer de conversatie gaat over meer dan de transacties afkomstig van de source). \n",
    "\n",
    "## signing van transactie\n",
    "Elke source ondertekend de transactie op basis van public key encryptie.\n",
    "De public key is eenvoudig op te vragen op een vast url bij de source host.\n",
    "Een destination host moet elke transactie op geldigheid controleren, en de public key opvragen bij de source host. De destination host is er verantwoordelijk voor om regelmatig te controleren dat het de laatste versie van de public key heeft. \n",
    " - VRAAG: hoe signeren we een data record, aangezien er niet een vaste tekst is die gebruikt wordt om de data te valideren. Of moeten we hier een json dump bij in zetten zodat iemand die kan controleren met de payload? dan gaat de data dubbel....\n",
    " - ik dacht zelf aan een JWT oplossing, maar die payload blijft dan nog een issue\n",
    " - op een later moment kan een proxy signeren voor een source host waar vanuit de destination geen contact mee is (geweest). Bijvoorbeeld als deze uit de lucht gaat. Vertrouwen is dan verlegd naar de proxy. Of de destination dan vertrouwd wat de proxy aangeeft is aan de destination.\n",
    "\n",
    "# Praktijken, Tags, Bijlagen, ...\n",
    "Het gefedereerd synchroniseren kan gaan over onderwijspraktijken, maar ook over bijvoorbeeld tags (metadata). Zodoende is een landelijke metadataset te gebruiken. Terwijl ondertussen niet gesyncroniseerde items per platform gebruikt kunnen worden. Niet bekende tags-gids op een destination host moeten daarom genegeerd worden. Een onderwijspraktijk getagged met een tag-gid kan via federatie teruggevonden worden omdat de tag-gid een eigen veld heeft, net als een praktijk. Maar elke bewerking op een tag is een transactie die ook een eigen gid heeft. Inclusief eigen inbox en outbox, abonnementen enzovoorts.\n",
    "\n",
    "# forks\n",
    "Forks (zoals binnen git bekend) van een item verwijzen naar hun voorliggende praktijken via de forked-from-gids (een lijst van gids).\n",
    "Meerdere parents zijn mogelijk. Omdat patching tussen de versies overdaad lijkt, kunnen we meerdere parents vooral bijhouden mochten er spinoffs komen en zo de impact vanuit de oorspronkelijke praktijk inzichtelijk te maken.\n",
    "\n",
    "# parent-transacties\n",
    "Een parent-transactie is het gid van de transactie waarbij de 'last known' transactie bij een edit opgeslagen staat. Dit is om concurrent editing aan hetzelfde item op te lossen via een 3way merge, vermoedelijk door een landelijke eddie.\n",
    " 1. slimfit eddie schrijft artikel xyz in transactie `abc`\n",
    " 2. slimfit pusht transactie `abc` naar landelijk\n",
    " 3. slimfit eddie gaat door met artikel xyz in transactie `def`, parent-transactie:`abc`\n",
    " 4. landelijke eddie bewerkt artikel xyz in transactie `fgh` met parent-transactie:`abc`\n",
    " 5. slimfit eddie pusht herziene artikel xyz met transactie `def` en parent-transactie `abc` naar landelijk\n",
    " 6. landelijke eddie krijgt melding dat xyz nu 2 versies heeft (uit `def` en `fgh` met dezelfde parent-transaction en voert een 3 way merge uit met resultaat in een nieuwe transactie `ghij`. vergelijkbaar met een gespleten head in git.\n",
    "\n",
    "\n",
    "# Cross-references\n",
    "Aangezien de inhoud altijd markdown is maar we wel graag willen verwijzen naar items (voor praktijken bijvoorbeeld) moet hiervoor een aparte notatie ontwikkeld worden. Bijvoorbeeld via `{item:gid}`, wat gebruikt  zou kunnen worden in een markdown link: `[Zie ook deze praktijk]({item:gid})` maar andere notaties zijn ook mogelijk. Als een artikel niet lokaal gesynced is (ivm filters of voorkeuren), zou het mooi zijn om een source url als alternatief op te nemen zodat een fallback ontstaat naar de bron: `{item:gid:https://fallbackurl}` Dit kan ook werken voor attachments als bijlagen en plaatjes.\n",
    "\n",
    "# Combinatie met caching:\n",
    "Omdat de caching mogelijkheid werkt met daadwerkelijke updates moet er na een wijziging gecontroleerd worden of er een update nodig is van een tabel met de laatste stand van zaken per entiteit (praktijken, tags, bijlagen, ...)\n",
    "\n",
    "# combinatie met applog\n",
    "Om statistieken per praktijk bij te houden in een gefedereerd systeem zijn een soort van pingbacks noodzakelijk. Dit is opgelost via de applog code, en wordt niet via gefedereerde synchronisatie geregeld. Dat gaat \"ouderwets\" client/server van het eindplatform naar landelijk waar de statistieken bekend zijn, en via een api op te vragen zijn voor elk artikel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# keyfiles\n",
    "Gegenereerd met `openssl genrsa -out jwt-key 4096` gevolgd door `openssl rsa -in jwt-key -pubout > jwt-key.pub`"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing RSA key\n",
      "writing RSA key\n",
      "writing RSA key\n",
      "writing RSA key\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for server in 'abcd':\n",
    "    os.system(f\"openssl genrsa -out {server}.jwt-key 4096\")\n",
    "    os.system(f\"openssl rsa -in {server}.jwt-key -pubout > {server}.jwt-key.pub\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Source code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from pydal import DAL, Field\n",
    "from pydal import SQLCustomType\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "import jwt\n",
    "import datetime\n",
    "import json\n",
    "from attrs import asdict\n",
    "\n",
    "GID_TYPE = SQLCustomType(\n",
    "    # http://web2py.com/book/default/chapter/06#Custom-Field-types\n",
    "    type='string',  # web2py type\n",
    "    native='uuid',\n",
    "    encoder=(lambda x: str(uuid.UUID(str(x)))),  # applied when the data is stored\n",
    "    decoder=(lambda x: uuid.UUID(x))  # applied when data is read\n",
    ")\n",
    "def not_guid(x):\n",
    "    return str(x) if isinstance(x, uuid.UUID) else x\n",
    "\n",
    "JSON_TYPE = SQLCustomType(\n",
    "    # http://web2py.com/book/default/chapter/06#Custom-Field-types\n",
    "    type='json',  # web2py type\n",
    "    native='json',\n",
    "    encoder=(lambda x: json.dumps({str(k):not_guid(v) for k,v in x.items()})),  # applied when the data is stored\n",
    "    decoder=(lambda x: x)  # applied when data is read\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from attrs import define\n",
    "import enum\n",
    "\n",
    "\n",
    "class AutoName(enum.Enum):\n",
    "    def _generate_next_value_(name, start, count, last_values):\n",
    "        return name\n",
    "\n",
    "\n",
    "class VisibilityScope(AutoName):\n",
    "    OWNER = enum.auto()\n",
    "    TEAM = enum.auto()\n",
    "    NETWORK = enum.auto()\n",
    "    DOMAIN = enum.auto()\n",
    "    PUBLIC = enum.auto()\n",
    "\n",
    "class TransactionSource(AutoName):\n",
    "    THIS = enum.auto()\n",
    "    EXTERN = enum.auto()\n",
    "\n",
    "@define\n",
    "class Transaction:\n",
    "    gid: uuid.UUID\n",
    "    claims: dict\n",
    "    scope: VisibilityScope\n",
    "    origin: str\n",
    "    author: str\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        self.claims['tr_gid'] = str(self.gid)\n",
    "        self.claims['scope'] = self.scope.value\n",
    "        self.claims['origin'] = self.origin\n",
    "        self.claims['author'] = self.author\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls,d):\n",
    "        return cls(\n",
    "            gid = d['tr_gid'],\n",
    "            claims = d,\n",
    "            scope=VisibilityScope[d['scope']],\n",
    "            origin=d['origin'],\n",
    "            author=d['author']\n",
    "        )\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, public_domain, db_uri, privkey_path: Path) -> None:\n",
    "        super().__init__()\n",
    "        self.audience = f\"urn:domain:{public_domain}\"  # domain name, or something similar.\n",
    "        self.db = DAL(db_uri)\n",
    "        self.db.define_table('query_subscribed',\n",
    "                             # pull from these servers\n",
    "                             Field('audience','string',length=256)\n",
    "                             )\n",
    "        self.db.define_table('notify_subscribed',\n",
    "                             # send to these servers\n",
    "                             Field('audience','string',length=256)\n",
    "                             )\n",
    "        self.db.define_table('document',\n",
    "                             Field('gid',GID_TYPE),\n",
    "                             Field('markdown','text'),\n",
    "                             Field('title','string'),\n",
    "                             Field('origin','string'),\n",
    "                             Field('authors','list:string'),\n",
    "                             )\n",
    "        self.db.define_table('transaction',\n",
    "                             Field('gid', GID_TYPE),\n",
    "                             Field('claims', JSON_TYPE),\n",
    "                             Field('scope', 'string', length=32),\n",
    "                             )\n",
    "        with privkey_path.open('r') as stream:\n",
    "            self.private_key = serialization.load_pem_private_key(\n",
    "                stream.read().strip().encode(), password=None, backend=default_backend()\n",
    "            )\n",
    "        with Path(privkey_path.name + '.pub').open('r') as stream:\n",
    "            self.public_key = stream.read()\n",
    "        self.public_keys = [path.open('r').read() for path in Path('.').glob('*.pub') if\n",
    "                            not path.name.startswith(privkey_path.name)]\n",
    "\n",
    "\n",
    "    def sign(self, claims: dict, audiences: list = None):\n",
    "        # add headers={} for additional headers\n",
    "        # https://pyjwt.readthedocs.io/en/latest/usage.html#registered-claim-names\n",
    "        # claims should be in the payload:\n",
    "        # {\"exp\": datetime.now(tz=timezone.utc)+ datetime.timedelta(seconds=30)} - do not allow reading after this time\n",
    "        # \"nbf\" works similarly, but is \"Not BeFore\"\n",
    "        # \"iss\" as ISSuer, string or URI, like \"urn:foo\"\n",
    "        claims['iss'] = self.audience  # public_uri\n",
    "        # \"aud\" is a list of possible audiences, if present the claim (when read) MUST provide one of the\n",
    "        # given audience records.\n",
    "        if audiences:\n",
    "            claims.setdefault('aud', [])\n",
    "            for audience in audiences:\n",
    "                if not audience.startswith('urn:'):\n",
    "                    raise ValueError(f'audience \"{audience}\" should start with \"urn:\"')\n",
    "                claims['aud'].append(audience)\n",
    "        claims[\"iat\"] = datetime.datetime.utcnow()\n",
    "        return jwt.encode(claims, self.private_key, algorithm='RS256')\n",
    "\n",
    "    def unsign(self, encoded_claims, with_audience=False):\n",
    "        if __debug__:\n",
    "            print(jwt.decode(signed, options={\"verify_signature\": False}))  # - without signature validation\n",
    "        options = {}\n",
    "        if with_audience:\n",
    "            options['audience'] = self.audience\n",
    "        return Transaction.from_dict(jwt.decode(encoded_claims, self.public_key, algorithms=[\"RS256\"], **options))\n",
    "\n",
    "    # def web_get_inbox(self):\n",
    "    #     \"only authenticated can request inbox, use to get all transactions received so far\"\n",
    "    #     ...\n",
    "\n",
    "    def web_post_inbox(self, signed_transaction):\n",
    "        \"posts from others to our inbox, could be subscriptions or private transactions\"\n",
    "        claim = self.unsign(signed_transaction)\n",
    "\n",
    "    def web_get_outbox(self):\n",
    "        \"Get public posts on display here, may include for the given requesting domain if authenticated\"\n",
    "        ...\n",
    "        # query transactions from transactions table for public scope or authenticated private scope\n",
    "        # use sync tools\n",
    "\n",
    "    # def web_post_outbox(self):\n",
    "    #     \"this server should be only one posting to the outbox\"\n",
    "    #     ...\n",
    "\n",
    "\n",
    "    def process_transaction(self, source: TransactionSource, transaction: Transaction):\n",
    "        # test if transaction already exist, and drop if so\n",
    "        db = self.db\n",
    "        if db(db.transaction.gid == transaction.gid).count() > 0:\n",
    "            if __debug__:\n",
    "                print(f\"{self.audience}: Not processing already processed transaction: {transaction.gid}\")\n",
    "            return\n",
    "        else:\n",
    "            # new transaction, save it as processed\n",
    "            self.db.transaction.insert(\n",
    "                gid=transaction.gid,\n",
    "                claims=transaction.claims,\n",
    "                scope=transaction.scope.value,\n",
    "            )\n",
    "        if source == TransactionSource.THIS:\n",
    "            # origin is here, so push outward to subscribed\n",
    "            db.commit()\n",
    "            for row in db(db.notify_subscribed).select():\n",
    "                print(f'Notify {row.audience} of transaction {transaction.gid}')\n",
    "                SERVERS[row.audience].web_post_inbox(self.sign(transaction.claims))\n",
    "        else:\n",
    "            # origin out there, so absorb in local: update document\n",
    "            transaction.claims.doc_gid\n",
    "        db.commit()\n",
    "\n",
    "    def new_document(self, title: str, markdown: str, scope: VisibilityScope):\n",
    "        gid = uuid.uuid4()\n",
    "        self.process_transaction(\n",
    "            TransactionSource.THIS,\n",
    "            transaction:=Transaction(\n",
    "                gid=uuid.uuid4(),\n",
    "                claims=dict(doc_gid=gid, title=title, markdown=markdown),\n",
    "                scope=scope,\n",
    "                origin=self.audience,\n",
    "                author='me@'+self.audience\n",
    "            )\n",
    "        )\n",
    "        return transaction\n",
    "\n",
    "    def update_document(\n",
    "            self,\n",
    "            gid: uuid.UUID,\n",
    "            title: str = None,\n",
    "            markdown: str = None,\n",
    "            scope: VisibilityScope = None,\n",
    "            origin: str = None,\n",
    "            author: str = None,\n",
    "\n",
    "    ):\n",
    "        document = self.db.document(gid=gid)\n",
    "        self.process_transaction(\n",
    "            TransactionSource.THIS,\n",
    "            transaction := Transaction(\n",
    "                uuid.uuid4(),\n",
    "                claims=dict(\n",
    "                    doc_gid = document.gid,\n",
    "                    title=title or document.title,\n",
    "                    markdown=markdown or document.markdown\n",
    "                ),\n",
    "                scope=scope or document.scope,\n",
    "                origin=origin or document.origin,\n",
    "                author=author or document.author\n",
    "            )\n",
    "        )\n",
    "        return transaction\n",
    "\n",
    "    def populate(self):\n",
    "        self.new_document('Padaboom!','Hier is nummer 1',VisibilityScope.OWNER)\n",
    "        self.db.commit()\n",
    "\n",
    "    def test(self):\n",
    "        print(self.db(self.db.transaction).select())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "server = os.getenv('POSTGRES_SERVER', '10.130.191.100')\n",
    "a = server_a = Server('a.edwh.nl', f'postgres://username:password@{server}/db_a', Path('a.jwt-key'))\n",
    "SERVERS:dict[str:Server] = {'a.edwh.nl':a}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction.id,transaction.gid,transaction.claims,transaction.scope\r\n",
      "1,bb62b4b6-6038-4056-be31-887cbe32ba6d,\"{'doc_gid': '2778f4e0-8d28-4295-998a-81bdbe4f89b8', 'title': 'Padaboom!', 'markdown': 'Hier is nummer 1', 'tr_gid': 'bb62b4b6-6038-4056-be31-887cbe32ba6d', 'scope': 'OWNER', 'origin': 'urn:domain:a.edwh.nl', 'author': 'me@urn:domain:a.edwh.nl'}\",OWNER\r\n",
      "2,55a1f222-8772-48c7-9258-588a85625cef,\"{'doc_gid': 'f8615ed0-1417-4615-8bfb-61c4c7d8d65e', 'title': 'Padaboom!', 'markdown': 'Hier is nummer 1', 'tr_gid': '55a1f222-8772-48c7-9258-588a85625cef', 'scope': 'OWNER', 'origin': 'urn:domain:a.edwh.nl', 'author': 'me@urn:domain:a.edwh.nl'}\",OWNER\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.db.rollback()\n",
    "a.populate()\n",
    "a.test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJtZXNzYWdlIjoiaG9pIiwidHJfZ2lkIjoib25iZWtlbmQiLCJzY29wZSI6Ik9XTkVSIiwib3JpZ2luIjoidXJuOmRvbWFpbjphLmVkd2gubmwiLCJhdXRob3IiOiJyZW1jb0BibGEiLCJpc3MiOiJ1cm46ZG9tYWluOmEuZWR3aC5ubCIsImF1ZCI6WyJ1cm46ZG9tYWluOmEuZWR3aC5ubCJdLCJpYXQiOjE2NjYzNjU5NTR9.MxIRvk3bXUaa-KXoD8AH9mybPf_VGNJpiCMnad7XTInvZCZSQaJJx4H7PX3lUPesslAjupXprA6WgFTHWryAvhZWe5LEQnXP8KJRcESjvupGOiDMaQSfx9nMeXQnUOmm2tJZEiR_p1DUva616UMAAhjxaOnnMNOAhzSD-hBinznHdxUGzHU0C4fSQtpfy-I62OGy1EqV67S2UmIvL9TWgnW75veVDH7LuK6ltAJsuF6AtUJsOGrfK_YKdbdljL-OgPWMUU1gokDCcPzUrBWHZna24gyL1jx0yNsZsUhn5VHBZPmsgbekcGHG6WQNgT7w1HY8bGx7BJTwFHkROC2xw9FbJuf_JL7PxX0d84RYf-bBQ8j1KaQr1u6FYBqeTWVFX4V2uqRmGZTvML-QI_xeP7ymD5UZmuK9aq4sfwQ2sYll54fps7tpnGGAC30gKU1pK_C62s21WDosLmRPP2oJ1Ift1seuzOoZuegSf1d8nd98oUhtbd2OlyXai_AYFnVt_NeOAKTKkKfbhvAWenY5-xcDeC4DTqdzYdoJfq7un7kCCn_lGWQX7YEPxEtFUhDb6-hP6eDtje_sTq872IlWFfRSuHDECwt3dyZTUECslogS_GeWZUoqJFBp9ti1DvhtDN1QOCqyy8V6c_EgtuzCBBvXXeeS0NNImNSFJWE1QME\n"
     ]
    }
   ],
   "source": [
    "signed = a.sign(dict(message='hoi', tr_gid='onbekend', scope='OWNER', origin=a.audience, author='remco@bla'), audiences=['urn:domain:a.edwh.nl'])\n",
    "print(signed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'hoi', 'tr_gid': 'onbekend', 'scope': 'OWNER', 'origin': 'urn:domain:a.edwh.nl', 'author': 'remco@bla', 'iss': 'urn:domain:a.edwh.nl', 'aud': ['urn:domain:a.edwh.nl'], 'iat': 1666365954}\n",
      "Transaction(gid='onbekend', claims={'message': 'hoi', 'tr_gid': 'onbekend', 'scope': 'OWNER', 'origin': 'urn:domain:a.edwh.nl', 'author': 'remco@bla', 'iss': 'urn:domain:a.edwh.nl', 'aud': ['urn:domain:a.edwh.nl'], 'iat': 1666365954}, scope=<VisibilityScope.OWNER: 'OWNER'>, origin='urn:domain:a.edwh.nl', author='remco@bla')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unsigned = a.unsign(signed, with_audience=True)\n",
    "print(unsigned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jwt.decode(signed, options={\"verify_signature\": False})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Transaction(gid=UUID('da455dba-b3d3-4736-b284-60d078040381'), claims={'tr_gid': 'da455dba-b3d3-4736-b284-60d078040381', 'scope': 'OWNER', 'origin': 'urn:domain:a.edwh.nl', 'author': 'me@urn:domain:a.edwh.nl'}, scope=<VisibilityScope.OWNER: 'OWNER'>, origin='urn:domain:a.edwh.nl', author='me@urn:domain:a.edwh.nl')"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Transaction(uuid.uuid4(), dict(), VisibilityScope.OWNER, a.audience, 'me@'+a.audience)\n",
    "t"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0cl9naWQiOiJkYTQ1NWRiYS1iM2QzLTQ3MzYtYjI4NC02MGQwNzgwNDAzODEiLCJzY29wZSI6Ik9XTkVSIiwib3JpZ2luIjoidXJuOmRvbWFpbjphLmVkd2gubmwiLCJhdXRob3IiOiJtZUB1cm46ZG9tYWluOmEuZWR3aC5ubCIsImlzcyI6InVybjpkb21haW46YS5lZHdoLm5sIiwiaWF0IjoxNjY2MzY0NDQyfQ.UlXc4B0h4on5qPQbF4eWCWnZyaKI0YC3Z-K3slnOj5UMWNY3qFncLu9wChDZfMwR3vPKHTF8DZ4cdcmP7GEQMuxjMueOi70bIgzNTLcTPOfrP5vCfOof-gZUUWHqpZwPQl5SfuGhX23yEhLBEUn5LzOHo_YAGS_AGun6s7APE0FwryEmzVZzUvBIFgh4EUByOJPfcaCbX9xWA8qxFAhf-3TYbhTFDMzahewl_sCZe-qWR0qLj_yx0LOXoyEA4WAsGDC0-RBtMx2aO5hwkjMEKkJl5qwXmHd0w_ENHoPME2YciiiJxjnkscuv8qCKVKYuAqufIPHK0qexIhebh8nRIMVLwESRSPSDPX-wiURj1sSZYcP63-Vm1lLayFmmjAIfRD8h5Cpug6fdQ32eepX1URpTAGJ3FKzERjTCZOxrdtkPaYWu3Ev1UIYt7DYqwwz6_Nm9lW_QwgxATJeLuTExURX105ZRRzqw4CCAkSrBJUzI_9BSaKS4f87f43IU_G8U6-735tlkHKfot_IXhLwbo_jqjA10cOc8wWWaz313tC0XczEzS4KPmJBnSlaoKeMr3xSjeW6IKRvs4-99z6VVhaHAmSGZa7p2WXbpTsa9W1oRs1mKnNgN0hFgIp7t2xR3e7opvqxVhfd1JdmDZyLrnHXOMRkbK9EnC2kuV984ThQ'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signed = a.sign(t.claims)\n",
    "signed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tr_gid': 'da455dba-b3d3-4736-b284-60d078040381', 'scope': 'OWNER', 'origin': 'urn:domain:a.edwh.nl', 'author': 'me@urn:domain:a.edwh.nl', 'iss': 'urn:domain:a.edwh.nl', 'iat': 1666364442}\n"
     ]
    }
   ],
   "source": [
    "unsigned = a.unsign(signed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Openstaande vragen\n",
    "1. moeten we origins per artikel hebben, of 1 genoeg?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
