Metadata-Version: 2.3
Name: careamics
Version: 0.1.0rc4
Summary: Toolbox for running N2V and friends.
Project-URL: homepage, https://careamics.github.io/
Project-URL: repository, https://github.com/CAREamics/careamics
Author-email: Igor Zubarev <igor.zubarev@fht.org>, Joran Deschamps <joran.deschamps@fht.org>
License: BSD-3-Clause
License-File: LICENSE
Classifier: Development Status :: 3 - Alpha
Classifier: License :: OSI Approved :: BSD License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Typing :: Typed
Requires-Python: >=3.8
Requires-Dist: albumentations
Requires-Dist: bioimageio-core>=0.6.0
Requires-Dist: psutil
Requires-Dist: pydantic>=2.5
Requires-Dist: pytorch-lightning>=2.2.0
Requires-Dist: pyyaml
Requires-Dist: scikit-image
Requires-Dist: tifffile
Requires-Dist: torch>=2.0.0
Requires-Dist: zarr
Provides-Extra: dev
Requires-Dist: pre-commit; extra == 'dev'
Requires-Dist: pytest; extra == 'dev'
Requires-Dist: pytest-cov; extra == 'dev'
Requires-Dist: sybil; extra == 'dev'
Provides-Extra: examples
Requires-Dist: careamics-portfolio; extra == 'examples'
Requires-Dist: jupyter; extra == 'examples'
Requires-Dist: matplotlib; extra == 'examples'
Provides-Extra: tensorboard
Requires-Dist: protobuf==3.20.3; extra == 'tensorboard'
Requires-Dist: tensorboard; extra == 'tensorboard'
Provides-Extra: wandb
Requires-Dist: wandb; extra == 'wandb'
Description-Content-Type: text/markdown

<p align="center">
  <a href="https://careamics.github.io/">
    <img src="https://raw.githubusercontent.com/CAREamics/.github/main/profile/images/banner_careamics.png">
  </a>
</p>

# CAREamics Restoration

[![License](https://img.shields.io/pypi/l/careamics.svg?color=green)](https://github.com/CAREamics/careamics/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/careamics.svg?color=green)](https://pypi.org/project/careamics)
[![Python Version](https://img.shields.io/pypi/pyversions/careamics.svg?color=green)](https://python.org)
[![CI](https://github.com/CAREamics/careamics/actions/workflows/ci.yml/badge.svg)](https://github.com/CAREamics/careamics/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/CAREamics/careamics/branch/main/graph/badge.svg)](https://codecov.io/gh/CAREamics/careamics)

## Installation

``` bash
pip install careamics
```
For more details on the options please follow the installation [guide](https://careamics.github.io/careamics/).

## Usage

CAREamics uses the Engine object to construct the pipeline for both training and prediction. First we import the Engine.
```python
from careamics_restoration.engine import Engine
```
The Engine could be initialized in 2 ways:
1. Using the [yaml config](examples/n2v_2D_reference.yml) file

Specify the mandatory parameters in the config file
```yaml
experiment_name: Name of the experiment
working_directory: Path to the working directory, where all the outputs will be stored

algorithm: 
    loss: type of loss function, e.g. n2v for Noise2Void
    model: model architecture, e.g. UNet
    is_3D: True if 3D data, False if 2D data

training:
  num_epochs: Number of training epochs
  patch_size: Size of the patches, List of 2 or 3 elements
  batch_size: Batch size for training

extraction_strategy: Controls how the patches are extracted from the data

data:
    data_format: File extension, e.g. tif
    axes: Defines the shape of the input data
```
Full description of the configuration parameters is in the [documentation](https://careamics.github.io/careamics/).


```python
engine = Engine(config_path="config.yml")

```
2. Using the path to the pretrained model
It's also possible to initialize the Engine using the model checkpoint, saved during the training or downloaded from the [BioImage Model Zoo](https://bioimage.io/#/).
Checkpoint must contain model_state_dict.
Read more abount saving and loading models in the [documentation](https://careamics.github.io/careamics/).

Once Engine is initialized, we can start training, providing the relative paths to train and validation data

```python
engine.train(train_path=train_path, val_path=val_path)
```
Training will run for the specified number of epochs and save the model checkpoint in the working directory.

Prediction could be done directly after the training or by loading the pretrained model checkpoint.

```python
predictions = engine.predict(pred_path=predict_path)
```

For more examples please take a look at the [notebooks](examples).

