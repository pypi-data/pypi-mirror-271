Custom Data Processors
=======================

Extend the functionality of Hyped by creating custom data processors tailored to your specific requirements. Custom data processors allow you to define custom data transformations, integrate with external libraries, or apply domain-specific logic to your data pipelines.

Implementing Custom Data Processors
------------------------------------

To implement a custom data processor in Hyped, you'll need to define a configuration class and a processor class. Here's how to get started:

1. **Define the Configuration Class**: Create a configuration class by subclassing :code:`BaseDataProcessorConfig` provided by Hyped. This class should be a Pydantic model and hold all the configurations for your processor. When defining the attributes of your configuration class, you can utilize special types to describe input features to be processed by the processor:

	- :code:`FeatureKey`: Represents a single feature key or name that identifies a specific input feature to be processed.

	- :code:`FeatureCollection`: Represents a collection of feature keys that belong to a group or category, allowing for the processing of multiple related features together.

	- :code:`FeatureDict`: Represents a dictionary of feature keys mapped to their corresponding configurations or settings, providing a structured way to define configurations for a set of features.

  For more information on this please refer to the :doc:`Feature Access Documentation <feature_access>`

2. **Define the Processor Class**: Create a processor class by subclassing :code:`BaseDataProcessor`. The processor class should be constructed from the configuration alone. You can overwrite the following functions in the processor class to customize its behavior:

    - :code:`def map_features(self, features: datasets.Features) -> datasets.Features`
      
      Takes in Hugging Face dataset features that are input to the processor and returns the features that are generated by the processor.

    - :code:`(async) def process(self, example: dict[str, Any], index: int, rank: int) -> dict[str, Any]`
      
      This function is responsible for performing the actual processing of a single example in the data pipeline. Optionally, you may define it as an async coroutine if you need asynchronous processing.

    - :code:`(async) def process(self, examples: dict[str, Any], index: int, rank: int) -> Iterator[dict[str, Any]]`
      
      This function defines a generator that yields processed examples. It allows for data augmentation or filtering by iterating through a batch of examples and yielding the processed versions. The use of the :code:`yield` keyword is required within this function for it to work as intended. Optionally, you may define it as an async coroutine for asynchronous processing.

    - :code:`def internal_batch_process(self, examples: dict[str, list[Any]], index: list[int], rank: int) -> tuple[dict[str, list[Any]], list[int]]`
      
      This function is responsible for processing a batch of examples in the form of :code:`dict[str, list[Any]]`. It should return the processed batch in the same form as well as a list of source indices indicating which input generated each output example.

Example
-------

Below is an example of how to implement a custom data processor in Hyped:

.. code-block:: python

    from datasets import Features, Value
    from hyped.common.feature_key import FeatureKey
    from hyped.data.processors.base import BaseDataProcessorConfig, BaseDataProcessor

    # Define the Configuration Class
    class MyCustomProcessorConfig(BaseDataProcessorConfig):
        # Define configuration parameters here
        feature: FeatureKey
        parameter1: str
        parameter2: int

    # Define the Processor Class
    class MyCustomProcessor(BaseDataProcessor[BaseDataProcessorConfig]):
        def __init__(self, config: MyCustomProcessorConfig) -> None:
            super().__init__(config)

        def map_features(self, features: Features) -> Features:
            # Implement feature mapping logic here
            feature = self.config.feature.index_features(features)
            return {"out": feature}

        def process(self, example: dict[str, Any], index: int, rank: int) -> dict[str, Any]:
            # Implement custom data processing logic here
            val = self.config.feature.index_example(example)
            return {"out": val}

This example demonstrates how to define a configuration class (:code:`MyCustomProcessorConfig`) and a processor class (:code:`MyCustomProcessor`). The configuration class holds all the configurations for the processor, and the processor class is constructed from the configuration alone.

Explore further examples and use cases to learn how to leverage custom data processors effectively in your Hyped workflows.

