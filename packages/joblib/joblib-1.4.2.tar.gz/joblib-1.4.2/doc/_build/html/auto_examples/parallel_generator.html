
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Returning a generator in joblib.Parallel &#8212; joblib 1.3.2 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Parallel examples" href="parallel/index.html" />
    <link rel="prev" title="Improving I/O using compressors" href="compressors_comparison.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-parallel-generator-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="returning-a-generator-in-joblib-parallel">
<span id="sphx-glr-auto-examples-parallel-generator-py"></span><h1>Returning a generator in joblib.Parallel<a class="headerlink" href="#returning-a-generator-in-joblib-parallel" title="Permalink to this headline">¶</a></h1>
<p>This example illustrates memory optimization enabled by using
<a class="reference internal" href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> to get a generator on the outputs of parallel jobs.
We first create tasks that return results with large memory footprints.
If we call <a class="reference internal" href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parallel</span></code></a> for several of these tasks directly, we
observe a high memory usage, as all the results are held in RAM before being
processed</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">return_as='generator'</span></code> allows to progressively consume the outputs
as they arrive and keeps the memory at an acceptable level.</p>
<p>In this case, the output of the <cite>Parallel</cite> call is a generator that yields the
results in the order the tasks have been submitted with. If the order of the
tasks does not matter (for instance if they are consumed by a commutative
aggregation function), then using <code class="docutils literal notranslate"><span class="pre">return_as='generator_unordered'</span></code> can be
even more efficient.</p>
<section id="memorymonitor-helper">
<h2><code class="docutils literal notranslate"><span class="pre">MemoryMonitor</span></code> helper<a class="headerlink" href="#memorymonitor-helper" title="Permalink to this headline">¶</a></h2>
<p>The following class is an helper to monitor the memory of the process and its
children in another thread, so we can display it afterward.</p>
<p>We will use <code class="docutils literal notranslate"><span class="pre">psutil</span></code> to monitor the memory usage in the code. Make sure it
is installed with <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">psutil</span></code> for this example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">psutil</span> <span class="kn">import</span> <span class="n">Process</span>
<span class="kn">from</span> <span class="nn">threading</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/threading.html#threading.Thread" title="threading.Thread" class="sphx-glr-backref-module-threading sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Thread</span></a>


<span class="k">class</span> <span class="nc">MemoryMonitor</span><span class="p">(</span><a href="https://docs.python.org/3/library/threading.html#threading.Thread" title="threading.Thread" class="sphx-glr-backref-module-threading sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Thread</span></a><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Monitor the memory usage in MB in a separate thread.</span>

<span class="sd">    Note that this class is good enough to highlight the memory profile of</span>
<span class="sd">    Parallel in this example, but is not a general purpose profiler fit for</span>
<span class="sd">    all cases.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">memory_buffer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;Get memory of a process and its children.&quot;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">Process</span><span class="p">()</span>
        <span class="n">memory</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
            <span class="n">memory</span> <span class="o">+=</span> <span class="n">c</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span><span class="o">.</span><span class="n">rss</span>
        <span class="k">return</span> <span class="n">memory</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">memory_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_memory</span><span class="p">()</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_memory</span><span class="p">()</span> <span class="o">-</span> <span class="n">memory_start</span><span class="p">)</span>
            <a href="https://docs.python.org/3/library/time.html#time.sleep" title="time.sleep" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">sleep</span></a><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">join</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="save-memory-by-consuming-the-outputs-of-the-tasks-as-fast-as-possible">
<h2>Save memory by consuming the outputs of the tasks as fast as possible<a class="headerlink" href="#save-memory-by-consuming-the-outputs-of-the-tasks-as-fast-as-possible" title="Permalink to this headline">¶</a></h2>
<p>We create a task whose output takes about 15MB of RAM.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">return_big_object</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
    <a href="https://docs.python.org/3/library/time.html#time.sleep" title="time.sleep" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">sleep</span></a><span class="p">(</span><span class="mf">.1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">i</span> <span class="o">*</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ones.html#numpy.ones" title="numpy.ones" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">ones</span></a><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">np</span><span class="o">.</span><span class="n">float64</span></a><span class="p">)</span>
</pre></div>
</div>
<p>We create a reduce step. The input will be a generator on big objects
generated in parallel by several instances of <code class="docutils literal notranslate"><span class="pre">return_big_object</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">accumulator_sum</span><span class="p">(</span><span class="n">generator</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">+=</span> <span class="n">value</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
<p>We process many of the tasks in parallel. If <code class="docutils literal notranslate"><span class="pre">return_as=&quot;list&quot;</span></code> (default),
we should expect a usage of more than 2GB in RAM. Indeed, all the results
are computed and stored in <code class="docutils literal notranslate"><span class="pre">res</span></code> before being processed by
<cite>accumulator_sum</cite> and collected by the gc.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <a href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Parallel</span></a><span class="p">,</span> <a href="../parallel.html#joblib.delayed" title="joblib.delayed" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-function"><span class="n">delayed</span></a>

<span class="n">monitor</span> <span class="o">=</span> <span class="n">MemoryMonitor</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running tasks with return_as=&#39;list&#39;...&quot;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <a href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Parallel</span></a><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_as</span><span class="o">=</span><span class="s2">&quot;list&quot;</span><span class="p">)(</span>
    <a href="../parallel.html#joblib.delayed" title="joblib.delayed" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-function"><span class="n">delayed</span></a><span class="p">(</span><span class="n">return_big_object</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">150</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accumulate results:&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">accumulator_sum</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;All tasks completed and reduced successfully.&#39;</span><span class="p">)</span>

<span class="c1"># Report memory usage</span>
<span class="k">del</span> <span class="n">res</span>  <span class="c1"># we clean the result to avoid memory border effects</span>
<span class="n">monitor</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="n">peak</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">monitor</span><span class="o">.</span><span class="n">memory_buffer</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak memory usage: </span><span class="si">{</span><span class="n">peak</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>If we use <code class="docutils literal notranslate"><span class="pre">return_as=&quot;generator&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">res</span></code> is simply a generator on the
results that are ready. Here we consume the results as soon as they arrive
with the <code class="docutils literal notranslate"><span class="pre">accumulator_sum</span></code> and once they have been used, they are collected
by the gc. The memory footprint is thus reduced, typically around 300MB.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">monitor_gen</span> <span class="o">=</span> <span class="n">MemoryMonitor</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Create result generator with return_as=&#39;generator&#39;...&quot;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <a href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Parallel</span></a><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_as</span><span class="o">=</span><span class="s2">&quot;generator&quot;</span><span class="p">)(</span>
    <a href="../parallel.html#joblib.delayed" title="joblib.delayed" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-function"><span class="n">delayed</span></a><span class="p">(</span><span class="n">return_big_object</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">150</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accumulate results:&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">accumulator_sum</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;All tasks completed and reduced successfully.&#39;</span><span class="p">)</span>

<span class="c1"># Report memory usage</span>
<span class="k">del</span> <span class="n">res</span>  <span class="c1"># we clean the result to avoid memory border effects</span>
<span class="n">monitor_gen</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="n">peak</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">monitor_gen</span><span class="o">.</span><span class="n">memory_buffer</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e6</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak memory usage: </span><span class="si">{</span><span class="n">peak</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">MB&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We can then report the memory usage accross time of the two runs using the
MemoryMonitor.</p>
<p>In the first case, as the results accumulate in <code class="docutils literal notranslate"><span class="pre">res</span></code>, the memory grows
linearly and it is freed once the <code class="docutils literal notranslate"><span class="pre">accumulator_sum</span></code> function finishes.</p>
<p>In the second case, the results are processed by the accumulator as soon as
they arrive, and the memory does not need to be able to contain all
the results.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">monitor</span><span class="o">.</span><span class="n">memory_buffer</span><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;return_as=&quot;list&quot;&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">monitor_gen</span><span class="o">.</span><span class="n">memory_buffer</span><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;return_as=&quot;generator&quot;&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([],</span> <span class="p">[])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Memory usage&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mf">1e7</span><span class="p">,</span> <span class="mf">1e8</span><span class="p">,</span> <span class="mf">1e9</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;10MB&#39;</span><span class="p">,</span> <span class="s1">&#39;100MB&#39;</span><span class="p">,</span> <span class="s1">&#39;1GB&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>It is important to note that with <code class="docutils literal notranslate"><span class="pre">return_as=&quot;generator&quot;</span></code>, the results are
still accumulated in RAM after computation. But as we asynchronously process
them, they can be freed sooner. However, if the generator is not consumed
the memory still grows linearly.</p>
</section>
<section id="further-memory-efficiency-for-commutative-aggregation">
<h2>Further memory efficiency for commutative aggregation<a class="headerlink" href="#further-memory-efficiency-for-commutative-aggregation" title="Permalink to this headline">¶</a></h2>
<p>There is still room for improving the relief on memory allocation we get
using <code class="docutils literal notranslate"><span class="pre">return_as=&quot;generator&quot;</span></code>. Indeed, notice how the generator of the
previous example respects the order the tasks have been submitted with. This
behavior can cause a build up in memory of results waiting to be consumed,
in case some tasks finished before other tasks despite being submitted
later. The corresponding results will be kept in memory until the slower
tasks submitted earlier are done and have been iterated over.</p>
<p>In case the downstream consumer of the results is reliant on the assumption
that the results are yielded in the same order that the tasks were submitted,
it can’t be helped. But in our example, since the <cite>+</cite> operator is
commutative, the function <code class="docutils literal notranslate"><span class="pre">accumulator_sum</span></code> does not need the generator to
return the results with any particular order. In this case it’s safe to use
the option <code class="docutils literal notranslate"><span class="pre">return_as=&quot;generator_unordered&quot;</span></code>, so that the results are
returned as soon as a task is completed, ignoring the order of task
submission.</p>
<p>Beware that the downstream consumer of the results must not expect them be
returned with any deterministic or predictable order at all, since the
progress of the tasks can depend on the availability of the workers, which
can be affected by external events, such as system load, implementation
details in the backend, etc.</p>
<p>To better highlight improvements in memory usage when using the parameter
<code class="docutils literal notranslate"><span class="pre">return_as=&quot;generator_unordered&quot;</span></code>, let’s explcitly add delay in some of
the submitted tasks.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">return_big_object_delayed</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">20</span><span class="p">)</span> <span class="o">%</span> <span class="mi">60</span><span class="p">:</span>
        <a href="https://docs.python.org/3/library/time.html#time.sleep" title="time.sleep" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">sleep</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <a href="https://docs.python.org/3/library/time.html#time.sleep" title="time.sleep" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">sleep</span></a><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">i</span> <span class="o">*</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ones.html#numpy.ones" title="numpy.ones" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">ones</span></a><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">np</span><span class="o">.</span><span class="n">float64</span></a><span class="p">)</span>
</pre></div>
</div>
<p>Let’s check memory usage when using <code class="docutils literal notranslate"><span class="pre">return_as=&quot;generator&quot;</span></code>…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">monitor_delayed_gen</span> <span class="o">=</span> <span class="n">MemoryMonitor</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Create result generator on delayed tasks with return_as=&#39;generator&#39;...&quot;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <a href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Parallel</span></a><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_as</span><span class="o">=</span><span class="s2">&quot;generator&quot;</span><span class="p">)(</span>
    <a href="../parallel.html#joblib.delayed" title="joblib.delayed" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-function"><span class="n">delayed</span></a><span class="p">(</span><span class="n">return_big_object_delayed</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">150</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accumulate results:&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">accumulator_sum</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;All tasks completed and reduced successfully.&#39;</span><span class="p">)</span>

<span class="c1"># Report memory usage</span>
<span class="k">del</span> <span class="n">res</span>  <span class="c1"># we clean the result to avoid memory border effects</span>
<span class="n">monitor_delayed_gen</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="n">peak</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">monitor_delayed_gen</span><span class="o">.</span><span class="n">memory_buffer</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e6</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak memory usage: </span><span class="si">{</span><span class="n">peak</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">MB&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>If we use <code class="docutils literal notranslate"><span class="pre">return_as=&quot;generator_unordered&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">res</span></code> will not enforce any
order when returning the results, and will simply enable iterating on the
results as soon as it’s available. The peak memory usage is now controlled
to an even lower level, since that results can be consumed immediately
rather than being delayed by the compute of slower tasks that have been
submitted earlier.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">monitor_delayed_gen_unordered</span> <span class="o">=</span> <span class="n">MemoryMonitor</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span>
  <span class="s2">&quot;Create result generator on delayed tasks with &quot;</span>
  <span class="s2">&quot;return_as=&#39;generator_unordered&#39;...&quot;</span>
<span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <a href="../generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Parallel</span></a><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_as</span><span class="o">=</span><span class="s2">&quot;generator_unordered&quot;</span><span class="p">)(</span>
    <a href="../parallel.html#joblib.delayed" title="joblib.delayed" class="sphx-glr-backref-module-joblib sphx-glr-backref-type-py-function"><span class="n">delayed</span></a><span class="p">(</span><span class="n">return_big_object_delayed</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">150</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accumulate results:&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">accumulator_sum</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;All tasks completed and reduced successfully.&#39;</span><span class="p">)</span>

<span class="c1"># Report memory usage</span>
<span class="k">del</span> <span class="n">res</span>  <span class="c1"># we clean the result to avoid memory border effects</span>
<span class="n">monitor_delayed_gen_unordered</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="n">peak</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">monitor_delayed_gen_unordered</span><span class="o">.</span><span class="n">memory_buffer</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e6</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak memory usage: </span><span class="si">{</span><span class="n">peak</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">MB&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice how the plot for <code class="docutils literal notranslate"><span class="pre">'return_as=&quot;generator'</span></code> now shows a high memory
usage plateau when slow jobs cause a congestion of intermediate results
waiting in RAM before in-order aggregation. This high memory usage is never
observed when using <code class="docutils literal notranslate"><span class="pre">'return_as=&quot;generator_unordered&quot;</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">monitor_delayed_gen</span><span class="o">.</span><span class="n">memory_buffer</span><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;return_as=&quot;generator&quot;&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">monitor_delayed_gen_unordered</span><span class="o">.</span><span class="n">memory_buffer</span><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;return_as=&quot;generator_unordered&quot;&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([],</span> <span class="p">[])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Memory usage&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mf">1e7</span><span class="p">,</span> <span class="mf">1e8</span><span class="p">,</span> <span class="mf">1e9</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;10MB&#39;</span><span class="p">,</span> <span class="s1">&#39;100MB&#39;</span><span class="p">,</span> <span class="s1">&#39;1GB&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.000 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-parallel-generator-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/3fa10e137733c0c23e90dca9a693a9e7/parallel_generator.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">parallel_generator.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/db658a25107c199addf4f0b83d7dc5ac/parallel_generator.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">parallel_generator.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/joblib_logo.svg" alt="Logo"/>
    
  </a>
</p>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">User manual</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../why.html">Why joblib: project goals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">Installing joblib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory.html">On demand recomputing: the <cite>Memory</cite> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel.html">Embarrassingly parallel for loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../persistence.html">Persistence</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html#id1">General examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#parallel-examples">Parallel examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../developing.html">Development</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Module reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.Memory.html">joblib.Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.Parallel.html">joblib.Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.parallel_config.html">joblib.parallel_config</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.dump.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.dump</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.load.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.load</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.hash.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.hash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.register_compressor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.register_compressor</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deprecated functionalities</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generated/joblib.parallel_backend.html">joblib.parallel_backend</a></li>
</ul>


        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2008-2021, Joblib developers.
      
      |
      <a href="../_sources/auto_examples/parallel_generator.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>