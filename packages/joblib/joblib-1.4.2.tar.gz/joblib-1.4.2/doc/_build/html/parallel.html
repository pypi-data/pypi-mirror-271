
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Embarrassingly parallel for loops &#8212; joblib 1.3.2 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Persistence" href="persistence.html" />
    <link rel="prev" title="On demand recomputing: the Memory class" href="memory.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="embarrassingly-parallel-for-loops">
<span id="parallel"></span><h1>Embarrassingly parallel for loops<a class="headerlink" href="#embarrassingly-parallel-for-loops" title="Permalink to this headline">¶</a></h1>
<section id="common-usage">
<h2>Common usage<a class="headerlink" href="#common-usage" title="Permalink to this headline">¶</a></h2>
<p>Joblib provides a simple helper class to write parallel for loops using
multiprocessing. The core idea is to write the code to be executed as a
generator expression, and convert it to parallel computing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">sqrt</span><span class="p">(</span><span class="n">i</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="go">[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]</span>
</pre></div>
</div>
<p>can be spread over 2 CPUs using the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">sqrt</span><span class="p">)(</span><span class="n">i</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="go">[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]</span>
</pre></div>
</div>
<p>The output can be a generator that yields the results as soon as they’re
available, even if the subsequent tasks aren’t completed yet. The order
of the outputs always matches the order the inputs have been submitted with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parallel</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_as</span><span class="o">=</span><span class="s2">&quot;generator&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_generator</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span><span class="n">delayed</span><span class="p">(</span><span class="n">sqrt</span><span class="p">)(</span><span class="n">i</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">output_generator</span><span class="p">))</span>
<span class="go">&lt;class &#39;generator&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">output_generator</span><span class="p">))</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">output_generator</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">output_generator</span><span class="p">))</span>
<span class="go">[2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]</span>
</pre></div>
</div>
<p>This generator enables reducing the memory footprint of
<a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> calls in case the results can benefit from on-the-fly
aggregation, as illustrated in
<a class="reference internal" href="auto_examples/parallel_generator.html#sphx-glr-auto-examples-parallel-generator-py"><span class="std std-ref">Returning a generator in joblib.Parallel</span></a>.</p>
<p>Future releases are planned to also support returning a generator that yields
the results in the order of completion rather than the order of submission, by
using <code class="docutils literal notranslate"><span class="pre">return_as=&quot;unordered_generator&quot;</span></code> instead of <code class="docutils literal notranslate"><span class="pre">return_as=&quot;generator&quot;</span></code>.
In this case the order of the outputs will depend on the concurrency of workers
and will not be guaranteed to be deterministic, meaning the results can be
yielded with a different order every time the code is executed.</p>
</section>
<section id="thread-based-parallelism-vs-process-based-parallelism">
<h2>Thread-based parallelism vs process-based parallelism<a class="headerlink" href="#thread-based-parallelism-vs-process-based-parallelism" title="Permalink to this headline">¶</a></h2>
<p>By default <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> uses the <code class="docutils literal notranslate"><span class="pre">'loky'</span></code> backend module to start
separate Python worker processes to execute tasks concurrently on
separate CPUs. This is a reasonable default for generic Python programs
but can induce a significant overhead as the input and output data need
to be serialized in a queue for communication with the worker processes (see
<a class="reference internal" href="#serialization-and-processes"><span class="std std-ref">Serialization &amp; Processes</span></a>).</p>
<p>When you know that the function you are calling is based on a compiled
extension that releases the Python Global Interpreter Lock (GIL) during
most of its computation then it is more efficient to use threads instead
of Python processes as concurrent workers. For instance this is the case
if you write the CPU intensive part of your code inside a <a class="reference external" href="https://docs.cython.org/src/userguide/external_C_code.html#acquiring-and-releasing-the-gil">with nogil</a>
block of a Cython function.</p>
<p>To hint that your code can efficiently use threads, just pass
<code class="docutils literal notranslate"><span class="pre">prefer=&quot;threads&quot;</span></code> as parameter of the <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> constructor.
In this case joblib will automatically use the <code class="docutils literal notranslate"><span class="pre">&quot;threading&quot;</span></code> backend
instead of the default <code class="docutils literal notranslate"><span class="pre">&quot;loky&quot;</span></code> backend:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">prefer</span><span class="o">=</span><span class="s2">&quot;threads&quot;</span><span class="p">)(</span>
<span class="gp">... </span>    <span class="n">delayed</span><span class="p">(</span><span class="n">sqrt</span><span class="p">)(</span><span class="n">i</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="go">[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="generated/joblib.parallel_config.html#joblib.parallel_config" title="joblib.parallel_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">parallel_config()</span></code></a> context manager helps selecting
a specific backend implementation or setting the default number of jobs:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">parallel_config</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">parallel_config</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;threading&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="gp">... </span>   <span class="n">Parallel</span><span class="p">()(</span><span class="n">delayed</span><span class="p">(</span><span class="n">sqrt</span><span class="p">)(</span><span class="n">i</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="go">[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]</span>
</pre></div>
</div>
<p>The latter is especially useful when calling a library that uses
<a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> internally without exposing backend selection as
part of its public API.</p>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">prefer=&quot;threads&quot;</span></code> option was introduced in joblib 0.12.
In prior versions, the same effect could be achieved by hardcoding a
specific backend implementation such as <code class="docutils literal notranslate"><span class="pre">backend=&quot;threading&quot;</span></code> in the
call to <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> but this is now considered a bad pattern
(when done in a library) as it does not make it possible to override that
choice with the <a class="reference internal" href="generated/joblib.parallel_config.html#joblib.parallel_config" title="joblib.parallel_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">parallel_config()</span></code></a> context manager.</p>
<div class="topic">
<p class="topic-title">The loky backend may not always be available</p>
<p>Some rare systems do not support multiprocessing (for instance
Pyodide). In this case the loky backend is not available and the
default backend falls back to threading.</p>
</div>
<p>In addition to the builtin joblib backends, there are several cluster-specific
backends you can use:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.dask.org/en/stable/">Dask</a> backend for Dask clusters
(see <a class="reference internal" href="auto_examples/parallel/distributed_backend_simple.html#sphx-glr-auto-examples-parallel-distributed-backend-simple-py"><span class="std std-ref">Using Dask for single-machine parallel computing</span></a> for an example),</p></li>
<li><p><a class="reference external" href="https://docs.ray.io/en/latest/index.html">Ray</a> backend for Ray clusters,</p></li>
<li><p><a class="reference external" href="https://github.com/joblib/joblib-spark">Joblib Apache Spark Backend</a>
to distribute joblib tasks on a Spark cluster.</p></li>
</ul>
</section>
<section id="serialization-processes">
<span id="serialization-and-processes"></span><h2>Serialization &amp; Processes<a class="headerlink" href="#serialization-processes" title="Permalink to this headline">¶</a></h2>
<p>To share function definition across multiple python processes, it is necessary to rely on a serialization protocol. The standard protocol in python is <a class="reference external" href="https://docs.python.org/3/library/pickle.html#module-pickle" title="(in Python v3.12)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pickle</span></code></a> but its default implementation in the standard library has several limitations. For instance, it cannot serialize functions which are defined interactively or in the <code class="code docutils literal notranslate"><span class="pre">__main__</span></code> module.</p>
<p>To avoid this limitation, the <code class="docutils literal notranslate"><span class="pre">loky</span></code> backend now relies on <a href="https://github.com/cloudpipe/cloudpickle"><code>cloudpickle</code></a> to serialize python objects. <a href="https://github.com/cloudpipe/cloudpickle"><code>cloudpickle</code></a> is an alternative implementation of the pickle protocol which allows the serialization of a greater number of objects, in particular interactively defined functions. So for most usages, the loky <code class="docutils literal notranslate"><span class="pre">backend</span></code> should work seamlessly.</p>
<p>The main drawback of <a href="https://github.com/cloudpipe/cloudpickle"><code>cloudpickle</code></a> is that it can be slower than the <a class="reference external" href="https://docs.python.org/3/library/pickle.html#module-pickle" title="(in Python v3.12)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pickle</span></code></a> module in the standard library. In particular, it is critical for large python dictionaries or lists, where the serialization time can be up to 100 times slower. There is two ways to alter the serialization process for the <code class="docutils literal notranslate"><span class="pre">joblib</span></code> to temper this issue:</p>
<ul class="simple">
<li><p>If you are on an UNIX system, you can switch back to the old <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> backend. With this backend, interactively defined functions can be shared with the worker processes using the fast <a class="reference external" href="https://docs.python.org/3/library/pickle.html#module-pickle" title="(in Python v3.12)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">pickle</span></code></a>. The main issue with this solution is that using <code class="docutils literal notranslate"><span class="pre">fork</span></code> to start the process breaks the standard POSIX and can have weird interaction with third party libraries such as <code class="docutils literal notranslate"><span class="pre">numpy</span></code> and <code class="docutils literal notranslate"><span class="pre">openblas</span></code>.</p></li>
<li><p>If you wish to use the <code class="docutils literal notranslate"><span class="pre">loky</span></code> backend with a different serialization library, you can set the <code class="docutils literal notranslate"><span class="pre">LOKY_PICKLER=mod_pickle</span></code> environment variable to use the <code class="docutils literal notranslate"><span class="pre">mod_pickle</span></code> as the serialization library for <code class="docutils literal notranslate"><span class="pre">loky</span></code>. The module <code class="docutils literal notranslate"><span class="pre">mod_pickle</span></code> passed as an argument should be importable as <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">mod_pickle</span></code> and should contain a <code class="docutils literal notranslate"><span class="pre">Pickler</span></code> object, which will be used to serialize to objects. It can be set to <code class="docutils literal notranslate"><span class="pre">LOKY_PICKLER=pickle</span></code> to use the pickling module from stdlib. The main drawback with <code class="docutils literal notranslate"><span class="pre">LOKY_PICKLER=pickle</span></code> is that interactively defined functions will not be serializable anymore. To cope with this, you can use this solution together with the <a class="reference internal" href="#joblib.wrap_non_picklable_objects" title="joblib.wrap_non_picklable_objects"><code class="xref py py-func docutils literal notranslate"><span class="pre">joblib.wrap_non_picklable_objects()</span></code></a> wrapper, which can be used as a decorator to locally enable using <a href="https://github.com/cloudpipe/cloudpickle"><code>cloudpickle</code></a> for specific objects. This way, you can have fast pickling of all python objects and locally enable slow pickling for interactive functions. An example is given in <a class="reference external" href="auto_examples/serialization_and_wrappers.html">loky_wrapper</a>.</p></li>
</ul>
</section>
<section id="shared-memory-semantics">
<h2>Shared-memory semantics<a class="headerlink" href="#shared-memory-semantics" title="Permalink to this headline">¶</a></h2>
<p>The default backend of joblib will run each function call in isolated
Python processes, therefore they cannot mutate a common Python object
defined in the main program.</p>
<p>However if the parallel function really needs to rely on the shared
memory semantics of threads, it should be made explicit with
<code class="docutils literal notranslate"><span class="pre">require='sharedmem'</span></code>, for instance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">shared_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">collect</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>   <span class="n">shared_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">require</span><span class="o">=</span><span class="s1">&#39;sharedmem&#39;</span><span class="p">)(</span>
<span class="gp">... </span>    <span class="n">delayed</span><span class="p">(</span><span class="n">collect</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
<span class="go">[None, None, None, None, None]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">shared_set</span><span class="p">)</span>
<span class="go">[0, 1, 2, 3, 4]</span>
</pre></div>
</div>
<p>Keep in mind that relying a on the shared-memory semantics is probably
suboptimal from a performance point of view as concurrent access to a
shared Python object will suffer from lock contention.</p>
</section>
<section id="reusing-a-pool-of-workers">
<h2>Reusing a pool of workers<a class="headerlink" href="#reusing-a-pool-of-workers" title="Permalink to this headline">¶</a></h2>
<p>Some algorithms require to make several consecutive calls to a parallel
function interleaved with processing of the intermediate results. Calling
<a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> several times in a loop is sub-optimal because it will
create and destroy a pool of workers (threads or processes) several times which
can cause a significant overhead.</p>
<p>For this case it is more efficient to use the context manager API of the
<a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> class to re-use the same pool of workers for several
calls to the <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> object:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="k">as</span> <span class="n">parallel</span><span class="p">:</span>
<span class="gp">... </span>   <span class="n">accumulator</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="gp">... </span>   <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">... </span>   <span class="k">while</span> <span class="n">accumulator</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>
<span class="gp">... </span>       <span class="n">results</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span><span class="n">delayed</span><span class="p">(</span><span class="n">sqrt</span><span class="p">)(</span><span class="n">accumulator</span> <span class="o">+</span> <span class="n">i</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>                          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
<span class="gp">... </span>       <span class="n">accumulator</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>  <span class="c1"># synchronization barrier</span>
<span class="gp">... </span>       <span class="n">n_iter</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">accumulator</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">)</span>                            
<span class="go">(1136.596..., 14)</span>
</pre></div>
</div>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">'loky'</span></code> backend now used by default for process-based
parallelism automatically tries to maintain and reuse a pool of workers
by it-self even for calls without the context manager.</p>
</section>
<section id="working-with-numerical-data-in-shared-memory-memmapping">
<h2>Working with numerical data in shared memory (memmapping)<a class="headerlink" href="#working-with-numerical-data-in-shared-memory-memmapping" title="Permalink to this headline">¶</a></h2>
<p>By default the workers of the pool are real Python processes forked using the
<code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> module of the Python standard library when <code class="docutils literal notranslate"><span class="pre">n_jobs</span> <span class="pre">!=</span> <span class="pre">1</span></code>.
The arguments passed as input to the <code class="docutils literal notranslate"><span class="pre">Parallel</span></code> call are serialized and
reallocated in the memory of each worker process.</p>
<p>This can be problematic for large arguments as they will be reallocated
<code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> times by the workers.</p>
<p>As this problem can often occur in scientific computing with <code class="docutils literal notranslate"><span class="pre">numpy</span></code>
based datastructures, <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> provides a special
handling for large arrays to automatically dump them on the filesystem
and pass a reference to the worker to open them as memory map
on that file using the <code class="docutils literal notranslate"><span class="pre">numpy.memmap</span></code> subclass of <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>.
This makes it possible to share a segment of data between all the
worker processes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following only applies with the <code class="docutils literal notranslate"><span class="pre">&quot;loky&quot;`</span> <span class="pre">and</span>
<span class="pre">``'multiprocessing'</span></code> process-backends. If your code can release the
GIL, then using a thread-based backend by passing
<code class="docutils literal notranslate"><span class="pre">prefer='threads'</span></code> is even more efficient because it makes it
possible to avoid the communication overhead of process-based
parallelism.</p>
<p>Scientific Python libraries such as numpy, scipy, pandas and
scikit-learn often release the GIL in performance critical code paths.
It is therefore advised to always measure the speed of thread-based
parallelism and use it when the scalability is not limited by the GIL.</p>
</div>
<section id="automated-array-to-memmap-conversion">
<h3>Automated array to memmap conversion<a class="headerlink" href="#automated-array-to-memmap-conversion" title="Permalink to this headline">¶</a></h3>
<p>The automated array to memmap conversion is triggered by a configurable
threshold on the size of the array:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">is_memmap</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_nbytes</span><span class="o">=</span><span class="mf">1e6</span><span class="p">)(</span>
<span class="gp">... </span>    <span class="n">delayed</span><span class="p">(</span><span class="n">is_memmap</span><span class="p">)(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">1e2</span><span class="p">,</span> <span class="mf">1e4</span><span class="p">,</span> <span class="mf">1e6</span><span class="p">])</span>
<span class="go">[False, False, True]</span>
</pre></div>
</div>
<p>By default the data is dumped to the <code class="docutils literal notranslate"><span class="pre">/dev/shm</span></code> shared-memory partition if it
exists and is writable (typically the case under Linux). Otherwise the
operating system’s temporary folder is used. The location of the temporary data
files can be customized by passing a <code class="docutils literal notranslate"><span class="pre">temp_folder</span></code> argument to the
<code class="docutils literal notranslate"><span class="pre">Parallel</span></code> constructor.</p>
<p>Passing <code class="docutils literal notranslate"><span class="pre">max_nbytes=None</span></code> makes it possible to disable the automated array to
memmap conversion.</p>
</section>
<section id="manual-management-of-memmapped-input-data">
<h3>Manual management of memmapped input data<a class="headerlink" href="#manual-management-of-memmapped-input-data" title="Permalink to this headline">¶</a></h3>
<p>For even finer tuning of the memory usage it is also possible to
dump the array as a memmap directly from the parent process to
free the memory before forking the worker processes. For instance
let’s allocate a large array in the memory of the parent process:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">large_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">))</span>
</pre></div>
</div>
<p>Dump it to a local file for memmapping:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tempfile</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">load</span><span class="p">,</span> <span class="n">dump</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">temp_folder</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temp_folder</span><span class="p">,</span> <span class="s1">&#39;joblib_test.mmap&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span> <span class="n">os</span><span class="o">.</span><span class="n">unlink</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">dump</span><span class="p">(</span><span class="n">large_array</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">large_memmap</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">mmap_mode</span><span class="o">=</span><span class="s1">&#39;r+&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">large_memmap</span></code> variable is pointing to a <code class="docutils literal notranslate"><span class="pre">numpy.memmap</span></code>
instance:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">large_memmap</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">large_array</span><span class="o">.</span><span class="n">nbytes</span><span class="p">,</span> <span class="n">large_array</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(&#39;memmap&#39;, 8000000, (1000000,))</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">large_array</span><span class="p">,</span> <span class="n">large_memmap</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<p>The original array can be freed from the main process memory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">del</span> <span class="n">large_array</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">gc</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
<p>It is possible to slice <code class="docutils literal notranslate"><span class="pre">large_memmap</span></code> into a smaller memmap:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">small_memmap</span> <span class="o">=</span> <span class="n">large_memmap</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">small_memmap</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">small_memmap</span><span class="o">.</span><span class="n">nbytes</span><span class="p">,</span> <span class="n">small_memmap</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(&#39;memmap&#39;, 24, (3,))</span>
</pre></div>
</div>
<p>Finally a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> view backed on that same memory mapped file can be
used:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">small_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">small_memmap</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">small_array</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">small_array</span><span class="o">.</span><span class="n">nbytes</span><span class="p">,</span> <span class="n">small_array</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(&#39;ndarray&#39;, 24, (3,))</span>
</pre></div>
</div>
<p>All those three datastructures point to the same memory buffer and
this same buffer will also be reused directly by the worker processes
of a <code class="docutils literal notranslate"><span class="pre">Parallel</span></code> call:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_nbytes</span><span class="o">=</span><span class="kc">None</span><span class="p">)(</span>
<span class="gp">... </span>    <span class="n">delayed</span><span class="p">(</span><span class="n">is_memmap</span><span class="p">)(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="p">[</span><span class="n">large_memmap</span><span class="p">,</span> <span class="n">small_memmap</span><span class="p">,</span> <span class="n">small_array</span><span class="p">])</span>
<span class="go">[True, True, True]</span>
</pre></div>
</div>
<p>Note that here <code class="docutils literal notranslate"><span class="pre">max_nbytes=None</span></code> is used to disable the auto-dumping
feature of <code class="docutils literal notranslate"><span class="pre">Parallel</span></code>. <code class="docutils literal notranslate"><span class="pre">small_array</span></code> is still in shared memory in the
worker processes because it was already backed by shared memory in the
parent process.
The pickling machinery of <code class="docutils literal notranslate"><span class="pre">Parallel</span></code> multiprocessing queues are
able to detect this situation and optimize it on the fly to limit
the number of memory copies.</p>
</section>
<section id="writing-parallel-computation-results-in-shared-memory">
<h3>Writing parallel computation results in shared memory<a class="headerlink" href="#writing-parallel-computation-results-in-shared-memory" title="Permalink to this headline">¶</a></h3>
<p>If data are opened using the <code class="docutils literal notranslate"><span class="pre">w+</span></code> or <code class="docutils literal notranslate"><span class="pre">r+</span></code> mode in the main program, the
worker will get <code class="docutils literal notranslate"><span class="pre">r+</span></code> mode access. Thus the worker will be able to write
its results directly to the original data, alleviating the need of the
serialization to send back the results to the parent process.</p>
<p>Here is an example script on parallel processing with preallocated
<code class="docutils literal notranslate"><span class="pre">numpy.memmap</span></code> datastructures
<a class="reference internal" href="auto_examples/parallel_memmap.html#sphx-glr-auto-examples-parallel-memmap-py"><span class="std std-ref">NumPy memmap in joblib.Parallel</span></a>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Having concurrent workers write on overlapping shared memory data segments,
for instance by using inplace operators and assignments on a <cite>numpy.memmap</cite>
instance, can lead to data corruption as numpy does not offer atomic
operations. The previous example does not risk that issue as each task is
updating an exclusive segment of the shared result array.</p>
<p>Some C/C++ compilers offer lock-free atomic primitives such as add-and-fetch
or compare-and-swap that could be exposed to Python via <a class="reference external" href="https://cffi.readthedocs.org">CFFI</a> for instance.
However providing numpy-aware atomic constructs is outside of the scope
of the joblib project.</p>
</div>
<p>A final note: don’t forget to clean up any temporary folder when you are done
with the computation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">shutil</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">try</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">temp_folder</span><span class="p">)</span>
<span class="gp">... </span><span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">pass</span>  <span class="c1"># this can sometimes fail under Windows</span>
</pre></div>
</div>
</section>
</section>
<section id="avoiding-over-subscription-of-cpu-resources">
<h2>Avoiding over-subscription of CPU resources<a class="headerlink" href="#avoiding-over-subscription-of-cpu-resources" title="Permalink to this headline">¶</a></h2>
<p>The computation parallelism relies on the usage of multiple CPUs to perform the
operation simultaneously. When using more processes than the number of CPU on
a machine, the performance of each process is degraded as there is less
computational power available for each process. Moreover, when many processes
are running, the time taken by the OS scheduler to switch between them can
further hinder the performance of the computation. It is generally better to
avoid using significantly more processes or threads than the number of CPUs on
a machine.</p>
<p>Some third-party libraries – <em>e.g.</em> the BLAS runtime used by <code class="docutils literal notranslate"><span class="pre">numpy</span></code> –
internally manage a thread-pool to perform their computations. The default
behavior is generally to use a number of threads equals to the number of CPUs
available. When these libraries are used with <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a>, each
worker will spawn its own thread-pools, resulting in a massive over-subscription
of resources that can slow down the computation compared to a sequential
one. To cope with this problem, joblib tells supported third-party libraries
to use a limited number of threads in workers managed by the <code class="docutils literal notranslate"><span class="pre">'loky'</span></code>
backend: by default each worker process will have environment variables set to
allow a maximum of <code class="docutils literal notranslate"><span class="pre">cpu_count()</span> <span class="pre">//</span> <span class="pre">n_jobs</span></code> so that the total number of
threads used by all the workers does not exceed the number of CPUs of the
host.</p>
<p>This behavior can be overridden by setting the proper environment variables to
the desired number of threads. This override is supported for the following
libraries:</p>
<blockquote>
<div><ul class="simple">
<li><p>OpenMP with the environment variable <code class="docutils literal notranslate"><span class="pre">'OMP_NUM_THREADS'</span></code>,</p></li>
<li><p>OpenBLAS with the <code class="docutils literal notranslate"><span class="pre">'OPENBLAS_NUM_THREADS'</span></code>,</p></li>
<li><p>MKL with the environment variable <code class="docutils literal notranslate"><span class="pre">'MKL_NUM_THREADS'</span></code>,</p></li>
<li><p>Accelerated with the environment variable <code class="docutils literal notranslate"><span class="pre">'VECLIB_MAXIMUM_THREADS'</span></code>,</p></li>
<li><p>Numexpr with the environment variable <code class="docutils literal notranslate"><span class="pre">'NUMEXPR_NUM_THREADS'</span></code>.</p></li>
</ul>
</div></blockquote>
<p>Since joblib 0.14, it is also possible to programmatically override the default
number of threads using the <code class="docutils literal notranslate"><span class="pre">inner_max_num_threads</span></code> argument of the
<a class="reference internal" href="generated/joblib.parallel_config.html#joblib.parallel_config" title="joblib.parallel_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">parallel_config()</span></code></a> function as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span><span class="p">,</span> <span class="n">parallel_config</span>

<span class="k">with</span> <span class="n">parallel_config</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;loky&quot;</span><span class="p">,</span> <span class="n">inner_max_num_threads</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">func</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>In this example, 4 Python worker processes will be allowed to use 2 threads
each, meaning that this program will be able to use up to 8 CPUs concurrently.</p>
</section>
<section id="custom-backend-api">
<h2>Custom backend API<a class="headerlink" href="#custom-backend-api" title="Permalink to this headline">¶</a></h2>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.10.</span></p>
</div>
<p>User can provide their own implementation of a parallel processing
backend in addition to the <code class="docutils literal notranslate"><span class="pre">'loky'</span></code>, <code class="docutils literal notranslate"><span class="pre">'threading'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'multiprocessing'</span></code> backends provided by default. A backend is
registered with the <a class="reference internal" href="#joblib.register_parallel_backend" title="joblib.register_parallel_backend"><code class="xref py py-func docutils literal notranslate"><span class="pre">joblib.register_parallel_backend()</span></code></a> function by
passing a name and a backend factory.</p>
<p>The backend factory can be any callable that returns an instance of
<code class="docutils literal notranslate"><span class="pre">ParallelBackendBase</span></code>. Please refer to the <a class="reference external" href="https://github.com/joblib/joblib/blob/master/joblib/_parallel_backends.py">default backends source code</a> as
a reference if you want to implement your own custom backend.</p>
<p>Note that it is possible to register a backend class that has some mandatory
constructor parameters such as the network address and connection credentials
for a remote cluster computing service:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyCustomBackend</span><span class="p">(</span><span class="n">ParallelBackendBase</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">api_key</span><span class="p">):</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span> <span class="o">=</span> <span class="n">endpoint</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">api_key</span>

    <span class="o">...</span>
    <span class="c1"># Do something with self.endpoint and self.api_key somewhere in</span>
    <span class="c1"># one of the method of the class</span>

<span class="n">register_parallel_backend</span><span class="p">(</span><span class="s1">&#39;custom&#39;</span><span class="p">,</span> <span class="n">MyCustomBackend</span><span class="p">)</span>
</pre></div>
</div>
<p>The connection parameters can then be passed to the
<a class="reference internal" href="generated/joblib.parallel_config.html#joblib.parallel_config" title="joblib.parallel_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">parallel_config()</span></code></a> context manager:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">parallel_config</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;custom&#39;</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="s1">&#39;http://compute&#39;</span><span class="p">,</span>
                     <span class="n">api_key</span><span class="o">=</span><span class="s1">&#39;42&#39;</span><span class="p">):</span>
    <span class="n">Parallel</span><span class="p">()(</span><span class="n">delayed</span><span class="p">(</span><span class="n">some_function</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<p>Using the context manager can be helpful when using a third-party library that
uses <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> internally while not exposing the <code class="docutils literal notranslate"><span class="pre">backend</span></code>
argument in its own API.</p>
<p>A problem exists that external packages that register new parallel backends
must now be imported explicitly for their backends to be identified by joblib:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">joblib</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">joblib</span><span class="o">.</span><span class="n">parallel_config</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;custom&#39;</span><span class="p">):</span>  
<span class="gp">... </span>    <span class="o">...</span>  <span class="c1"># this fails</span>
<span class="go">KeyError: &#39;custom&#39;</span>

<span class="go"># Import library to register external backend</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">my_custom_backend_library</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">joblib</span><span class="o">.</span><span class="n">parallel_config</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;custom&#39;</span><span class="p">):</span>  
<span class="gp">... </span>    <span class="o">...</span> <span class="c1"># this works</span>
</pre></div>
</div>
<p>This can be confusing for users.  To resolve this, external packages can
safely register their backends directly within the joblib codebase by creating
a small function that registers their backend, and including this function
within the <code class="docutils literal notranslate"><span class="pre">joblib.parallel.EXTERNAL_PACKAGES</span></code> dictionary:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_register_custom</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">my_custom_library</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;an informative error message&quot;</span><span class="p">)</span>

<span class="n">EXTERNAL_BACKENDS</span><span class="p">[</span><span class="s1">&#39;custom&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_register_custom</span>
</pre></div>
</div>
<p>This is subject to community review, but can reduce the confusion for users
when relying on side effects of external package imports.</p>
</section>
<section id="old-multiprocessing-backend">
<h2>Old multiprocessing backend<a class="headerlink" href="#old-multiprocessing-backend" title="Permalink to this headline">¶</a></h2>
<p>Prior to version 0.12, joblib used the <code class="docutils literal notranslate"><span class="pre">'multiprocessing'</span></code> backend as
default backend instead of <code class="docutils literal notranslate"><span class="pre">'loky'</span></code>.</p>
<p>This backend creates an instance of <cite>multiprocessing.Pool</cite> that forks
the Python interpreter in multiple processes to execute each of the
items of the list. The <cite>delayed</cite> function is a simple trick to be able
to create a tuple <cite>(function, args, kwargs)</cite> with a function-call
syntax.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Under Windows, the use of <code class="docutils literal notranslate"><span class="pre">multiprocessing.Pool</span></code> requires to
protect the main loop of code to avoid recursive spawning of
subprocesses when using <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a>. In other words, you
should be writing code like this when using the <code class="docutils literal notranslate"><span class="pre">'multiprocessing'</span></code>
backend:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">....</span>

<span class="k">def</span> <span class="nf">function1</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="o">...</span>

<span class="k">def</span> <span class="nf">function2</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="o">...</span>

<span class="o">...</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1"># do stuff with imports and functions defined about</span>
    <span class="o">...</span>
</pre></div>
</div>
<p><strong>No</strong> code should <em>run</em> outside of the <code class="docutils literal notranslate"><span class="pre">&quot;if</span> <span class="pre">__name__</span> <span class="pre">==</span>
<span class="pre">'__main__'&quot;</span></code> blocks, only imports and definitions.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">'loky'</span></code> backend used by default in joblib 0.12 and later does
not impose this anymore.</p>
</div>
</section>
<section id="bad-interaction-of-multiprocessing-and-third-party-libraries">
<h2>Bad interaction of multiprocessing and third-party libraries<a class="headerlink" href="#bad-interaction-of-multiprocessing-and-third-party-libraries" title="Permalink to this headline">¶</a></h2>
<p>Using the <code class="docutils literal notranslate"><span class="pre">'multiprocessing'</span></code> backend can cause a crash when using
third party libraries that manage their own native thread-pool if the
library is first used in the main process and subsequently called again
in a worker process (inside the <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> call).</p>
<p>Joblib version 0.12 and later are no longer subject to this problem
thanks to the use of <a class="reference external" href="https://github.com/tomMoral/loky">loky</a> as the
new default backend for process-based parallelism.</p>
<p>Prior to Python 3.4 the <code class="docutils literal notranslate"><span class="pre">'multiprocessing'</span></code> backend of joblib can only
use the <code class="docutils literal notranslate"><span class="pre">fork</span></code> strategy to create worker processes under non-Windows
systems. This can cause some third-party libraries to crash or freeze.
Such libraries include Apple vecLib / Accelerate (used by NumPy under
OSX), some old version of OpenBLAS (prior to 0.2.10) or the OpenMP
runtime implementation from GCC which is used internally by third-party
libraries such as XGBoost, spaCy, OpenCV…</p>
<p>The best way to avoid this problem is to use the <code class="docutils literal notranslate"><span class="pre">'loky'</span></code> backend
instead of the <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code> backend. Prior to joblib 0.12, it is
also possible  to get <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> configured to use the
<code class="docutils literal notranslate"><span class="pre">'forkserver'</span></code> start method on Python 3.4 and later. The start method
has to be configured by setting the <code class="docutils literal notranslate"><span class="pre">JOBLIB_START_METHOD</span></code> environment
variable to <code class="docutils literal notranslate"><span class="pre">'forkserver'</span></code> instead of the default <code class="docutils literal notranslate"><span class="pre">'fork'</span></code> start
method. However the user should be aware that using the <code class="docutils literal notranslate"><span class="pre">'forkserver'</span></code>
method prevents <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> to call function interactively
defined in a shell session.</p>
<p>You can read more on this topic in the <a class="reference external" href="https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods">multiprocessing documentation</a>.</p>
<p>Under Windows the <code class="docutils literal notranslate"><span class="pre">fork</span></code> system call does not exist at all so this problem
does not exist (but multiprocessing has more overhead).</p>
</section>
<section id="parallel-reference-documentation">
<h2><cite>Parallel</cite> reference documentation<a class="headerlink" href="#parallel-reference-documentation" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">joblib.</span></span><span class="sig-name descname"><span class="pre">Parallel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_as</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'list'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_dispatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'2</span> <span class="pre">*</span> <span class="pre">n_jobs'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temp_folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_nbytes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default('1M')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mmap_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default('r')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">require</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Helper class for readable parallel mapping.</p>
<p>Read more in the <a class="reference internal" href="#parallel"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>n_jobs: int, default: None</strong></dt><dd><p>The maximum number of concurrently running jobs, such as the number
of Python worker processes when backend=”multiprocessing”
or the size of the thread-pool when backend=”threading”.
If -1 all CPUs are used.
If 1 is given, no parallel computing code is used at all, and the
behavior amounts to a simple python <cite>for</cite> loop. This mode is not
compatible with <cite>timeout</cite>.
For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for
n_jobs = -2, all CPUs but one are used.
None is a marker for ‘unset’ that will be interpreted as n_jobs=1
unless the call is performed under a <a class="reference internal" href="generated/joblib.parallel_config.html#joblib.parallel_config" title="joblib.parallel_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">parallel_config()</span></code></a>
context manager that sets another value for <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code>.</p>
</dd>
<dt><strong>backend: str, ParallelBackendBase instance or None, default: ‘loky’</strong></dt><dd><p>Specify the parallelization backend implementation.
Supported backends are:</p>
<ul class="simple">
<li><p>“loky” used by default, can induce some
communication and memory overhead when exchanging input and
output data with the worker Python processes. On some rare
systems (such as Pyiodide), the loky backend may not be
available.</p></li>
<li><p>“multiprocessing” previous process-based backend based on
<cite>multiprocessing.Pool</cite>. Less robust than <cite>loky</cite>.</p></li>
<li><p>“threading” is a very low-overhead backend but it suffers
from the Python Global Interpreter Lock if the called function
relies a lot on Python objects. “threading” is mostly useful
when the execution bottleneck is a compiled extension that
explicitly releases the GIL (for instance a Cython loop wrapped
in a “with nogil” block or an expensive call to a library such
as NumPy).</p></li>
<li><p>finally, you can register backends by calling
<a class="reference internal" href="#joblib.register_parallel_backend" title="joblib.register_parallel_backend"><code class="xref py py-func docutils literal notranslate"><span class="pre">register_parallel_backend()</span></code></a>. This will allow you to
implement a backend of your liking.</p></li>
</ul>
<p>It is not recommended to hard-code the backend name in a call to
<a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parallel</span></code></a> in a library. Instead it is recommended to set
soft hints (prefer) or hard constraints (require) so as to make it
possible for library users to change the backend from the outside
using the <a class="reference internal" href="generated/joblib.parallel_config.html#joblib.parallel_config" title="joblib.parallel_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">parallel_config()</span></code></a> context manager.</p>
</dd>
<dt><strong>return_as: str in {‘list’, ‘generator’}, default: ‘list’</strong></dt><dd><p>If ‘list’, calls to this instance will return a list, only when
all results have been processed and retrieved.
If ‘generator’, it will return a generator that yields the results
as soon as they are available, in the order the tasks have been
submitted with.
Future releases are planned to also support ‘generator_unordered’,
in which case the generator immediately yields available results
independently of the submission order.</p>
</dd>
<dt><strong>prefer: str in {‘processes’, ‘threads’} or None, default: None</strong></dt><dd><p>Soft hint to choose the default backend if no specific backend
was selected with the <a class="reference internal" href="generated/joblib.parallel_config.html#joblib.parallel_config" title="joblib.parallel_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">parallel_config()</span></code></a> context manager.
The default process-based backend is ‘loky’ and the default
thread-based backend is ‘threading’. Ignored if the <code class="docutils literal notranslate"><span class="pre">backend</span></code>
parameter is specified.</p>
</dd>
<dt><strong>require: ‘sharedmem’ or None, default None</strong></dt><dd><p>Hard constraint to select the backend. If set to ‘sharedmem’,
the selected backend will be single-host and thread-based even
if the user asked for a non-thread based backend with
<a class="reference internal" href="generated/joblib.parallel_config.html#joblib.parallel_config" title="joblib.parallel_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">parallel_config()</span></code></a>.</p>
</dd>
<dt><strong>verbose: int, optional</strong></dt><dd><p>The verbosity level: if non zero, progress messages are
printed. Above 50, the output is sent to stdout.
The frequency of the messages increases with the verbosity level.
If it more than 10, all iterations are reported.</p>
</dd>
<dt><strong>timeout: float, optional</strong></dt><dd><p>Timeout limit for each task to complete.  If any task takes longer
a TimeOutError will be raised. Only applied when n_jobs != 1</p>
</dd>
<dt><strong>pre_dispatch: {‘all’, integer, or expression, as in ‘3*n_jobs’}</strong></dt><dd><p>The number of batches (of tasks) to be pre-dispatched.
Default is ‘2*n_jobs’. When batch_size=”auto” this is reasonable
default and the workers should never starve. Note that only basic
arithmetics are allowed here and no modules can be used in this
expression.</p>
</dd>
<dt><strong>batch_size: int or ‘auto’, default: ‘auto’</strong></dt><dd><p>The number of atomic tasks to dispatch at once to each
worker. When individual evaluations are very fast, dispatching
calls to workers can be slower than sequential computation because
of the overhead. Batching fast computations together can mitigate
this.
The <code class="docutils literal notranslate"><span class="pre">'auto'</span></code> strategy keeps track of the time it takes for a
batch to complete, and dynamically adjusts the batch size to keep
the time on the order of half a second, using a heuristic. The
initial batch size is 1.
<code class="docutils literal notranslate"><span class="pre">batch_size=&quot;auto&quot;</span></code> with <code class="docutils literal notranslate"><span class="pre">backend=&quot;threading&quot;</span></code> will dispatch
batches of a single task at a time as the threading backend has
very little overhead and using larger batch size has not proved to
bring any gain in that case.</p>
</dd>
<dt><strong>temp_folder: str, optional</strong></dt><dd><p>Folder to be used by the pool for memmapping large arrays
for sharing memory with worker processes. If None, this will try in
order:</p>
<ul class="simple">
<li><p>a folder pointed by the JOBLIB_TEMP_FOLDER environment
variable,</p></li>
<li><p>/dev/shm if the folder exists and is writable: this is a
RAM disk filesystem available by default on modern Linux
distributions,</p></li>
<li><p>the default system temporary folder that can be
overridden with TMP, TMPDIR or TEMP environment
variables, typically /tmp under Unix operating systems.</p></li>
</ul>
<p>Only active when backend=”loky” or “multiprocessing”.</p>
</dd>
<dt><strong>max_nbytes int, str, or None, optional, 1M by default</strong></dt><dd><p>Threshold on the size of arrays passed to the workers that
triggers automated memory mapping in temp_folder. Can be an int
in Bytes, or a human-readable string, e.g., ‘1M’ for 1 megabyte.
Use None to disable memmapping of large arrays.
Only active when backend=”loky” or “multiprocessing”.</p>
</dd>
<dt><strong>mmap_mode: {None, ‘r+’, ‘r’, ‘w+’, ‘c’}, default: ‘r’</strong></dt><dd><p>Memmapping mode for numpy arrays passed to workers. None will
disable memmapping, other modes defined in the numpy.memmap doc:
<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.memmap.html">https://numpy.org/doc/stable/reference/generated/numpy.memmap.html</a>
Also, see ‘max_nbytes’ parameter documentation for more details.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This object uses workers to compute in parallel the application of a
function to many different arguments. The main functionality it brings
in addition to using the raw multiprocessing or concurrent.futures API
are (see examples for details):</p>
<ul class="simple">
<li><p>More readable code, in particular since it avoids
constructing list of arguments.</p></li>
<li><dl class="simple">
<dt>Easier debugging:</dt><dd><ul>
<li><p>informative tracebacks even when the error happens on
the client side</p></li>
<li><p>using ‘n_jobs=1’ enables to turn off parallel computing
for debugging without changing the codepath</p></li>
<li><p>early capture of pickling errors</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>An optional progress meter.</p></li>
<li><p>Interruption of multiprocesses jobs with ‘Ctrl-C’</p></li>
<li><p>Flexible pickling control for the communication to and from
the worker processes.</p></li>
<li><p>Ability to use shared memory efficiently with worker
processes for large numpy-based datastructures.</p></li>
</ul>
<p>Note that the intended usage is to run one call at a time. Multiple
calls to the same Parallel object will result in a <code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code></p>
<p class="rubric">Examples</p>
<p>A simple example:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">sqrt</span><span class="p">)(</span><span class="n">i</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="go">[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]</span>
</pre></div>
</div>
<p>Reshaping the output when the function has several return
values:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">modf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">modf</span><span class="p">)(</span><span class="n">i</span><span class="o">/</span><span class="mf">2.</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">r</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span>
<span class="go">(0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span>
<span class="go">(0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0)</span>
</pre></div>
</div>
<p>The progress meter: the higher the value of <cite>verbose</cite>, the more
messages:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">)(</span>
<span class="gp">... </span>    <span class="n">delayed</span><span class="p">(</span><span class="n">sleep</span><span class="p">)(</span><span class="mf">.2</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span> 
<span class="go">[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.6s</span>
<span class="go">[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.8s</span>
<span class="go">[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    1.4s finished</span>
</pre></div>
</div>
<p>Traceback example, note how the line of the error is indicated
as well as the values of the parameter passed to the function that
triggered the exception, even though the traceback happens in the
child process:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">heapq</span> <span class="kn">import</span> <span class="n">nlargest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span>
<span class="gp">... </span><span class="n">delayed</span><span class="p">(</span><span class="n">nlargest</span><span class="p">)(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="s1">&#39;abcde&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">... </span>
<span class="go">-----------------------------------------------------------------------</span>
<span class="go">Sub-process traceback:</span>
<span class="go">-----------------------------------------------------------------------</span>
<span class="go">TypeError                                      Mon Nov 12 11:37:46 2012</span>
<span class="go">PID: 12934                                Python 2.7.3: /usr/bin/python</span>
<span class="go">........................................................................</span>
<span class="go">/usr/lib/python2.7/heapq.pyc in nlargest(n=2, iterable=3, key=None)</span>
<span class="go">    419         if n &gt;= size:</span>
<span class="go">    420             return sorted(iterable, key=key, reverse=True)[:n]</span>
<span class="go">    421</span>
<span class="go">    422     # When key is none, use simpler decoration</span>
<span class="go">    423     if key is None:</span>
<span class="go">--&gt; 424         it = izip(iterable, count(0,-1))           # decorate</span>
<span class="go">    425         result = _nlargest(n, it)</span>
<span class="go">    426         return map(itemgetter(0), result)          # undecorate</span>
<span class="go">    427</span>
<span class="go">    428     # General case, slowest method</span>
<span class="go"> TypeError: izip argument #1 must support iteration</span>
<span class="go">_______________________________________________________________________</span>
</pre></div>
</div>
<p>Using pre_dispatch in a producer/consumer situation, where the
data is generated on the fly. Note how the producer is first
called 3 times before the parallel loop is initiated, and then
called to generate new data on the fly:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">producer</span><span class="p">():</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Produced </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">yield</span> <span class="n">i</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="s1">&#39;1.5*n_jobs&#39;</span><span class="p">)(</span>
<span class="gp">... </span>    <span class="n">delayed</span><span class="p">(</span><span class="n">sqrt</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">producer</span><span class="p">())</span> 
<span class="go">Produced 0</span>
<span class="go">Produced 1</span>
<span class="go">Produced 2</span>
<span class="go">[Parallel(n_jobs=2)]: Done 1 jobs     | elapsed:  0.0s</span>
<span class="go">Produced 3</span>
<span class="go">[Parallel(n_jobs=2)]: Done 2 jobs     | elapsed:  0.0s</span>
<span class="go">Produced 4</span>
<span class="go">[Parallel(n_jobs=2)]: Done 3 jobs     | elapsed:  0.0s</span>
<span class="go">Produced 5</span>
<span class="go">[Parallel(n_jobs=2)]: Done 4 jobs     | elapsed:  0.0s</span>
<span class="go">[Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s remaining: 0.0s</span>
<span class="go">[Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s finished</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">dispatch_next</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Dispatch more data for parallel processing</p>
<p>This method is meant to be called concurrently by the multiprocessing
callback. We rely on the thread-safety of dispatch_one_batch to protect
against concurrent consumption of the unprotected iterator.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">dispatch_one_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iterator</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Prefetch the tasks for the next batch and dispatch them.</p>
<p>The effective size of the batch is computed here.
If there are no more jobs to dispatch, return False, else return True.</p>
<p>The iterator consumption and dispatching is protected by the same
lock so calling this function should be thread safe.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">format</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Return the formatted representation of the object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">print_progress</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Display the process of the parallel execution only a fraction
of time, controlled by self.verbose.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="joblib.delayed">
<span class="sig-prename descclassname"><span class="pre">joblib.</span></span><span class="sig-name descname"><span class="pre">delayed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">function</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#joblib.delayed" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorator used to capture the arguments of a function.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">joblib.</span></span><span class="sig-name descname"><span class="pre">parallel_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">backend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temp_folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_nbytes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default('1M')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mmap_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default('r')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">require</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">default(None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_max_num_threads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">backend_params</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Set the default backend or configuration for <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parallel</span></code></a>.</p>
<p>This is an alternative to directly passing keyword arguments to the
<a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parallel</span></code></a> class constructor. It is particularly useful when
calling into library code that uses joblib internally but does not expose
the various parallel configuration arguments in its own API.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>backend</strong><span class="classifier">str or ParallelBackendBase instance, default=None</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">backend</span></code> is a string it must match a previously registered
implementation using the <a class="reference internal" href="#joblib.register_parallel_backend" title="joblib.register_parallel_backend"><code class="xref py py-func docutils literal notranslate"><span class="pre">register_parallel_backend()</span></code></a> function.</p>
<p>By default the following backends are available:</p>
<ul class="simple">
<li><p>‘loky’: single-host, process-based parallelism (used by default),</p></li>
<li><p>‘threading’: single-host, thread-based parallelism,</p></li>
<li><p>‘multiprocessing’: legacy single-host, process-based parallelism.</p></li>
</ul>
<p>‘loky’ is recommended to run functions that manipulate Python objects.
‘threading’ is a low-overhead alternative that is most efficient for
functions that release the Global Interpreter Lock: e.g. I/O-bound
code or CPU-bound code in a few calls to native code that explicitly
releases the GIL. Note that on some rare systems (such as pyodide),
multiprocessing and loky may not be available, in which case joblib
defaults to threading.</p>
<p>In addition, if the <code class="docutils literal notranslate"><span class="pre">dask</span></code> and <code class="docutils literal notranslate"><span class="pre">distributed</span></code> Python packages are
installed, it is possible to use the ‘dask’ backend for better
scheduling of nested parallel calls without over-subscription and
potentially distribute parallel calls over a networked cluster of
several hosts.</p>
<p>It is also possible to use the distributed ‘ray’ backend for
distributing the workload to a cluster of nodes. See more details
in the Examples section below.</p>
<p>Alternatively the backend can be passed directly as an instance.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier">int, default=None</span></dt><dd><p>The maximum number of concurrently running jobs, such as the number
of Python worker processes when <code class="docutils literal notranslate"><span class="pre">backend=&quot;loky&quot;</span></code> or the size of the
thread-pool when <code class="docutils literal notranslate"><span class="pre">backend=&quot;threading&quot;</span></code>.
If -1 all CPUs are used. If 1 is given, no parallel computing code
is used at all, which is useful for debugging. For <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> below -1,
(n_cpus + 1 + n_jobs) are used. Thus for <code class="docutils literal notranslate"><span class="pre">n_jobs=-2</span></code>, all
CPUs but one are used.
<code class="docutils literal notranslate"><span class="pre">None</span></code> is a marker for ‘unset’ that will be interpreted as
<code class="docutils literal notranslate"><span class="pre">n_jobs=1</span></code> in most backends.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">int, default=0</span></dt><dd><p>The verbosity level: if non zero, progress messages are
printed. Above 50, the output is sent to stdout.
The frequency of the messages increases with the verbosity level.
If it more than 10, all iterations are reported.</p>
</dd>
<dt><strong>temp_folder</strong><span class="classifier">str, default=None</span></dt><dd><p>Folder to be used by the pool for memmapping large arrays
for sharing memory with worker processes. If None, this will try in
order:</p>
<ul class="simple">
<li><p>a folder pointed by the <code class="docutils literal notranslate"><span class="pre">JOBLIB_TEMP_FOLDER</span></code> environment
variable,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/dev/shm</span></code> if the folder exists and is writable: this is a
RAM disk filesystem available by default on modern Linux
distributions,</p></li>
<li><p>the default system temporary folder that can be
overridden with <code class="docutils literal notranslate"><span class="pre">TMP</span></code>, <code class="docutils literal notranslate"><span class="pre">TMPDIR</span></code> or <code class="docutils literal notranslate"><span class="pre">TEMP</span></code> environment
variables, typically <code class="docutils literal notranslate"><span class="pre">/tmp</span></code> under Unix operating systems.</p></li>
</ul>
</dd>
<dt><strong>max_nbytes int, str, or None, optional, default=’1M’</strong></dt><dd><p>Threshold on the size of arrays passed to the workers that
triggers automated memory mapping in temp_folder. Can be an int
in Bytes, or a human-readable string, e.g., ‘1M’ for 1 megabyte.
Use None to disable memmapping of large arrays.</p>
</dd>
<dt><strong>mmap_mode: {None, ‘r+’, ‘r’, ‘w+’, ‘c’}, default=’r’</strong></dt><dd><p>Memmapping mode for numpy arrays passed to workers. None will
disable memmapping, other modes defined in the numpy.memmap doc:
<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.memmap.html">https://numpy.org/doc/stable/reference/generated/numpy.memmap.html</a>
Also, see ‘max_nbytes’ parameter documentation for more details.</p>
</dd>
<dt><strong>prefer: str in {‘processes’, ‘threads’} or None, default=None</strong></dt><dd><p>Soft hint to choose the default backend.
The default process-based backend is ‘loky’ and the default
thread-based backend is ‘threading’. Ignored if the <code class="docutils literal notranslate"><span class="pre">backend</span></code>
parameter is specified.</p>
</dd>
<dt><strong>require: ‘sharedmem’ or None, default=None</strong></dt><dd><p>Hard constraint to select the backend. If set to ‘sharedmem’,
the selected backend will be single-host and thread-based.</p>
</dd>
<dt><strong>inner_max_num_threads</strong><span class="classifier">int, default=None</span></dt><dd><p>If not None, overwrites the limit set on the number of threads
usable in some third-party library threadpools like OpenBLAS,
MKL or OpenMP. This is only used with the <code class="docutils literal notranslate"><span class="pre">loky</span></code> backend.</p>
</dd>
<dt><strong>backend_params</strong><span class="classifier">dict</span></dt><dd><p>Additional parameters to pass to the backend constructor when
backend is a string.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Joblib tries to limit the oversubscription by limiting the number of
threads usable in some third-party library threadpools like OpenBLAS, MKL
or OpenMP. The default limit in each worker is set to
<code class="docutils literal notranslate"><span class="pre">max(cpu_count()</span> <span class="pre">//</span> <span class="pre">effective_n_jobs,</span> <span class="pre">1)</span></code> but this limit can be
overwritten with the <code class="docutils literal notranslate"><span class="pre">inner_max_num_threads</span></code> argument which will be used
to set this limit in the child processes.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.</span></p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">neg</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">parallel_config</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;threading&#39;</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">Parallel</span><span class="p">()(</span><span class="n">delayed</span><span class="p">(</span><span class="n">neg</span><span class="p">)(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="gp">...</span>
<span class="go">[-1, -2, -3, -4, -5]</span>
</pre></div>
</div>
<p>To use the ‘ray’ joblib backend add the following lines:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ray.util.joblib</span> <span class="kn">import</span> <span class="n">register_ray</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">register_ray</span><span class="p">()</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">parallel_config</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;ray&quot;</span><span class="p">):</span>  
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">Parallel</span><span class="p">()(</span><span class="n">delayed</span><span class="p">(</span><span class="n">neg</span><span class="p">)(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="go">[-1, -2, -3, -4, -5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="joblib.wrap_non_picklable_objects">
<span class="sig-prename descclassname"><span class="pre">joblib.</span></span><span class="sig-name descname"><span class="pre">wrap_non_picklable_objects</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_wrapper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#joblib.wrap_non_picklable_objects" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for non-picklable object to use cloudpickle to serialize them.</p>
<p>Note that this wrapper tends to slow down the serialization process as it
is done with cloudpickle which is typically slower compared to pickle. The
proper way to solve serialization issues is to avoid defining functions and
objects in the main scripts and to implement __reduce__ functions for
complex classes.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="joblib.register_parallel_backend">
<span class="sig-prename descclassname"><span class="pre">joblib.</span></span><span class="sig-name descname"><span class="pre">register_parallel_backend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">make_default</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#joblib.register_parallel_backend" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a new Parallel backend factory.</p>
<p>The new backend can then be selected by passing its name as the backend
argument to the <a class="reference internal" href="generated/joblib.Parallel.html#joblib.Parallel" title="joblib.Parallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parallel</span></code></a> class. Moreover, the default backend can
be overwritten globally by setting make_default=True.</p>
<p>The factory can be any callable that takes no argument and return an
instance of <code class="docutils literal notranslate"><span class="pre">ParallelBackendBase</span></code>.</p>
<p>Warning: this function is experimental and subject to change in a future
version of joblib.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.10.</span></p>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="joblib.parallel.ParallelBackendBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">joblib.parallel.</span></span><span class="sig-name descname"><span class="pre">ParallelBackendBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nesting_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_max_num_threads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#joblib.parallel.ParallelBackendBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper abc which defines all methods a ParallelBackend must implement</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="joblib.parallel.AutoBatchingMixin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">joblib.parallel.</span></span><span class="sig-name descname"><span class="pre">AutoBatchingMixin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#joblib.parallel.AutoBatchingMixin" title="Permalink to this definition">¶</a></dt>
<dd><p>A helper class for automagically batching jobs.</p>
</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/joblib_logo.svg" alt="Logo"/>
    
  </a>
</p>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">User manual</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="why.html">Why joblib: project goals</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing.html">Installing joblib</a></li>
<li class="toctree-l1"><a class="reference internal" href="memory.html">On demand recomputing: the <cite>Memory</cite> class</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Embarrassingly parallel for loops</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#common-usage">Common usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#thread-based-parallelism-vs-process-based-parallelism">Thread-based parallelism vs process-based parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="#serialization-processes">Serialization &amp; Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#shared-memory-semantics">Shared-memory semantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#reusing-a-pool-of-workers">Reusing a pool of workers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#working-with-numerical-data-in-shared-memory-memmapping">Working with numerical data in shared memory (memmapping)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#avoiding-over-subscription-of-cpu-resources">Avoiding over-subscription of CPU resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-backend-api">Custom backend API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#old-multiprocessing-backend">Old multiprocessing backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bad-interaction-of-multiprocessing-and-third-party-libraries">Bad interaction of multiprocessing and third-party libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parallel-reference-documentation"><cite>Parallel</cite> reference documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="persistence.html">Persistence</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="developing.html">Development</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Module reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="generated/joblib.Memory.html">joblib.Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="generated/joblib.Parallel.html">joblib.Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="generated/joblib.parallel_config.html">joblib.parallel_config</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="generated/joblib.dump.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.dump</a></li>
<li class="toctree-l1"><a class="reference internal" href="generated/joblib.load.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.load</a></li>
<li class="toctree-l1"><a class="reference internal" href="generated/joblib.hash.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.hash</a></li>
<li class="toctree-l1"><a class="reference internal" href="generated/joblib.register_compressor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.register_compressor</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deprecated functionalities</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="generated/joblib.parallel_backend.html">joblib.parallel_backend</a></li>
</ul>


        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2008-2021, Joblib developers.
      
      |
      <a href="_sources/parallel.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>