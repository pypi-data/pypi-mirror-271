Metadata-Version: 2.1
Name: llm-watsonx
Version: 0.1.0
Summary: LLM plugin for IBM watsonx models
Author: Robby Horvath
License: Apache-2.0
Project-URL: Homepage, https://github.com/h0rv/llm-watsonx
Project-URL: Changelog, https://github.com/h0rv/llm-watsonx/releases
Project-URL: Issues, https://github.com/h0rv/llm-watsonx/issues
Classifier: License :: OSI Approved :: Apache Software License
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: llm
Requires-Dist: ibm-watsonx-ai>=1.0.1
Provides-Extra: test
Requires-Dist: pytest; extra == "test"

# llm-watsonx

## Installation

Install this plugin in the same environment as LLM. From the current directory

```bash
llm install llm-watsonx
```

## Configuration

You will need to provide the following:

- API Key from IBM Cloud IAM: https://cloud.ibm.com/iam/apikeys
- Project ID (from watsonx.ai instance URL: https://dataplatform.cloud.ibm.com/projects//)

```bash
export WATSONX_API_KEY=
export WATSONX_PROJECT_ID=
```

- Optionally, if your watsonx instance is not in `us-south`:

```bash
export WATSONX_URL=
```

## Usage

Get list of commands:

```bash
llm watsonx --help
```

### Models

See all available models:

```bash
llm watsonx list-models
```

See all generation options:

```bash
llm watsonx list-model-options
```

#### Example

```bash
llm -m watsonx/meta-llama/llama-3-8b-instruct \
    -o temperature .4 \
    -o max_new_tokens 250 \
    "What is IBM watsonx?"
```

#### Chat Example

```bash
llm chat -m watsonx/meta-llama/llama-3-8b-instruct \
    -o max_new_tokens 1000 \
    -s "You are chatbot assistant for a CLI (command line interface). Provide and help give users with unix commands to acieve their tasks"
```

### Embeddings

See all available models:

```bash
llm watsonx list-embedding-models
```

#### Example

```bash
cat README.md | llm embed -m watsonx/ibm/slate-30m-english-rtrvr
```
