# You can create your own structure, ordering the keys for readability under substructures like 'budget'
# 'monitoring' and so on
run_args:
  # Specify the file path for NePS to load your pipeline and the name of the function.
  run_pipeline:
    path: "hpo_example.py"
    name: "training_pipeline"
  # Provide the path from which NePS can load the pipeline_space.
  pipeline_space: "pipeline_space.yaml"

  # Path for storing optimization progress/process.
  root_directory: "example_run_alternative"

  budget:
    # Caps the total number of configurations to test, controlling the experiment's length.
    max_evaluations_total: 20
    # Sets a resource usage limit (e.g., computational time), stopping new evaluations once reached.
    max_cost_total:

  monitoring:
    # Clears root_directory at start, useful for clean-slate runs or debugging.
    overwrite_working_directory: True

    # Generates a CSV summary post-optimization, detailing performance, best configs, and error counts.
    post_run_summary: True

    # Tags results within root_directory for multi-stage projects, avoiding clutter.
    development_stage_id: None

    # Similar to development_stage_id, but for categorizing tasks, aiding in results organization.
    task_id: None

  parallelization_setup:
    # Restricts evaluations per neps.run call, useful for managing resource allocation.
    max_evaluations_per_run:
    # Ensures continued sampling until a set number of evaluations finish, optimizing for time constraints.
    continue_until_max_evaluation_completed: False

  error_handling:
    # Assigns a default loss to failed evaluations, allowing the optimization to proceed.
    loss_value_on_error: None

    # Assigns a default cost to failed evaluations, useful for budget management.
    cost_value_on_error: None

    # Continues optimization past errors without stopping, counting them towards the total evaluation limit.
    ignore_errors: False

  search:
    # Chooses the optimization strategy, either from built-in options or via a custom BaseOptimizer.
    searcher: "bayesian_optimization"

    # Specifies a path to a custom searcher algorithm, for advanced customization.
    searcher_path:

    # Passes extra arguments to the searcher, tailoring its settings.
    searcher_kwargs:
      initial_design_size: 5
      surrogate_model: gp

  # List of functions to execute before loading results, for setup or preprocessing needs.
  pre_load_hooks:
