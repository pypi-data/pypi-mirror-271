[LOCALE]
plugin.name = Chat with files (Llama-index, inline)
plugin.description = Integrates Llama-index (Chat with files) storage in any chat and provides additional knowledge into context (from files and from context history in database)

prompt.label = Prompt
prompt.description = Prompt used for instruct how to use additional data provided from Llama-index.

ask_llama_first.label = Ask Llama-index first
ask_llama_first.description = When enabled, then Llama-index will be asked first, and response will be used as additional knowledge in prompt. When disabled, then Llama-index will be asked only when needed. INFO: Disabled in autonomous mode (via plugin)!

prepare_question.label = Auto-prepare question before asking Llama-index first
prepare_question.description = When enabled, then question will be prepared before asking Llama-index first to create best query.

model_prepare_question.label = Model for question preparation
model_prepare_question.description = Model used to prepare question before asking Llama-index, default: gpt-3.5-turbo

prepare_question_max_tokens.label = Max output tokens for question preparation
prepare_question_max_tokens.description = Max tokens in output when preparing question before asking Llama-index.

max_question_chars.label = Max characters in question
max_question_chars.description = Max characters in question when querying Llama-index, 0 = no limit.

syntax_prepare_question.label = Prompt for question preparation
syntax_prepare_question.description = System prompt for question preparation.

append_meta.label = Append metadata to context
append_meta.description = If enabled, then metadata from Llama-index will be appended to additional context

model_query.label = Model
model_query.description = Model used for querying Llama-index, default: gpt-3.5-turbo.

idx.label = Indexes to use
idx.description = ID's of indexes to use, default: base, separate by comma if you want to use more than one index at once.
